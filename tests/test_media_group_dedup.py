#!/usr/bin/env python3
"""
Test script to verify media group deduplication fix
This simulates the race condition where multiple messages with the same media_group_id
arrive almost simultaneously (within milliseconds of each other).
"""
import time

# Track media groups to process only once per task
processed_media_groups = set()
processed_media_groups_order = []


def register_processed_media_group(key):
    """Register a media group as processed (same as in main.py)"""
    if not key:
        return
    processed_media_groups.add(key)
    processed_media_groups_order.append(key)
    if len(processed_media_groups_order) > 300:
        old_key = processed_media_groups_order.pop(0)
        processed_media_groups.discard(old_key)


def simulate_message_handler(user_id, watch_key, media_group_id, message_num):
    """
    Simulates the auto_forward handler processing a message.
    Returns True if processed, False if skipped.
    """
    # Build media_group_key (same as in main.py line 1937)
    media_group_key = f"{user_id}_{watch_key}_{media_group_id}"
    
    # Check if already processed (same as in main.py line 1938-1940)
    if media_group_key in processed_media_groups:
        print(f"  æ¶ˆæ¯{message_num}: â­ï¸ è·³è¿‡ï¼šåª’ä½“ç»„å·²å¤„ç† (media_group_key={media_group_key})")
        return False
    
    # Simulate passing all filters
    print(f"  æ¶ˆæ¯{message_num}: ğŸ¯ æ¶ˆæ¯é€šè¿‡æ‰€æœ‰è¿‡æ»¤è§„åˆ™ï¼Œå‡†å¤‡å¤„ç†")
    
    # **FIX: Mark media group as processed immediately** (same as main.py line 1996-1998)
    if media_group_key:
        register_processed_media_group(media_group_key)
        print(f"  æ¶ˆæ¯{message_num}: âœ… å·²æ ‡è®°åª’ä½“ç»„ä¸ºå·²å¤„ç†: {media_group_key}")
    
    # Simulate forwarding (this takes time in reality)
    print(f"  æ¶ˆæ¯{message_num}: ğŸ“¤ è½¬å‘æ¨¡å¼ï¼šå¼€å§‹å¤„ç†")
    time.sleep(0.01)  # Simulate forwarding delay
    print(f"  æ¶ˆæ¯{message_num}: âœ… æ¶ˆæ¯å·²è½¬å‘")
    
    return True


def test_media_group_race_condition():
    """Test the race condition fix for media groups"""
    print("ğŸ§ª æµ‹è¯•åª’ä½“ç»„ç«æ€æ¡ä»¶ä¿®å¤\n")
    print("="*70)
    
    # Test 1: Single message (no media group)
    print("\næµ‹è¯• 1: å•æ¡æ¶ˆæ¯ï¼ˆæ— åª’ä½“ç»„ï¼‰")
    print("-" * 70)
    processed = simulate_message_handler("12345", "source|dest", None, 1)
    assert processed == True, "âŒ å¤±è´¥ï¼šå•æ¡æ¶ˆæ¯æœªè¢«å¤„ç†"
    print("âœ… é€šè¿‡ï¼šå•æ¡æ¶ˆæ¯æ­£å¸¸å¤„ç†\n")
    
    # Test 2: Media group with 4 images (simulating the original issue)
    print("æµ‹è¯• 2: åª’ä½“ç»„ï¼ˆ4å¼ å›¾ç‰‡ï¼‰- æ¨¡æ‹ŸåŸå§‹é—®é¢˜")
    print("-" * 70)
    print("åœºæ™¯ï¼šå‘é€4å¼ å›¾ç‰‡ï¼ŒTelegramåˆ†å‰²æˆ4æ¡æ¶ˆæ¯ï¼ŒåŒä¸€ä¸ª media_group_id")
    print("é¢„æœŸï¼šåªå¤„ç†ç¬¬ä¸€æ¡ï¼Œåç»­3æ¡è¢«è·³è¿‡\n")
    
    user_id = "12345"
    watch_key = "source|dest"
    media_group_id = "abc123def456"  # Same media_group_id for all 4 messages
    
    processed_count = 0
    skipped_count = 0
    
    # Simulate 4 messages arriving in rapid succession
    for i in range(1, 5):
        print(f"T+{(i-1)*57}ms: æ¶ˆæ¯{i}åˆ°è¾¾")
        if simulate_message_handler(user_id, watch_key, media_group_id, i):
            processed_count += 1
        else:
            skipped_count += 1
        print()
    
    print(f"ç»“æœç»Ÿè®¡:")
    print(f"  - å¤„ç†æ¬¡æ•°: {processed_count}")
    print(f"  - è·³è¿‡æ¬¡æ•°: {skipped_count}")
    print()
    
    assert processed_count == 1, f"âŒ å¤±è´¥ï¼šåª’ä½“ç»„è¢«å¤„ç†äº† {processed_count} æ¬¡ï¼Œåº”è¯¥åªå¤„ç†1æ¬¡"
    assert skipped_count == 3, f"âŒ å¤±è´¥ï¼šåªè·³è¿‡äº† {skipped_count} æ¡æ¶ˆæ¯ï¼Œåº”è¯¥è·³è¿‡3æ¡"
    print("âœ… é€šè¿‡ï¼šåª’ä½“ç»„åªè¢«å¤„ç†1æ¬¡ï¼Œå…¶ä½™3æ¬¡è¢«æ­£ç¡®è·³è¿‡\n")
    
    # Test 3: Different media groups should be processed separately
    print("æµ‹è¯• 3: ä¸åŒçš„åª’ä½“ç»„åº”è¯¥åˆ†åˆ«å¤„ç†")
    print("-" * 70)
    
    # Clear the cache for this test
    processed_media_groups.clear()
    processed_media_groups_order.clear()
    
    media_group_id_1 = "group_001"
    media_group_id_2 = "group_002"
    
    print(f"åª’ä½“ç»„1 (ID: {media_group_id_1}):")
    processed_1 = simulate_message_handler(user_id, watch_key, media_group_id_1, 1)
    print()
    
    print(f"åª’ä½“ç»„2 (ID: {media_group_id_2}):")
    processed_2 = simulate_message_handler(user_id, watch_key, media_group_id_2, 2)
    print()
    
    assert processed_1 == True, "âŒ å¤±è´¥ï¼šåª’ä½“ç»„1æœªè¢«å¤„ç†"
    assert processed_2 == True, "âŒ å¤±è´¥ï¼šåª’ä½“ç»„2æœªè¢«å¤„ç†"
    print("âœ… é€šè¿‡ï¼šä¸åŒåª’ä½“ç»„åˆ†åˆ«å¤„ç†\n")
    
    # Test 4: Same media group ID but different watch tasks should be processed separately
    print("æµ‹è¯• 4: ç›¸åŒåª’ä½“ç»„IDä½†ä¸åŒç›‘æ§ä»»åŠ¡åº”è¯¥åˆ†åˆ«å¤„ç†")
    print("-" * 70)
    
    processed_media_groups.clear()
    processed_media_groups_order.clear()
    
    media_group_id = "shared_group"
    watch_key_1 = "source1|dest1"
    watch_key_2 = "source2|dest2"
    
    print(f"ç›‘æ§ä»»åŠ¡1 ({watch_key_1}):")
    processed_1 = simulate_message_handler(user_id, watch_key_1, media_group_id, 1)
    print()
    
    print(f"ç›‘æ§ä»»åŠ¡2 ({watch_key_2}):")
    processed_2 = simulate_message_handler(user_id, watch_key_2, media_group_id, 2)
    print()
    
    assert processed_1 == True, "âŒ å¤±è´¥ï¼šç›‘æ§ä»»åŠ¡1æœªè¢«å¤„ç†"
    assert processed_2 == True, "âŒ å¤±è´¥ï¼šç›‘æ§ä»»åŠ¡2æœªè¢«å¤„ç†"
    print("âœ… é€šè¿‡ï¼šä¸åŒç›‘æ§ä»»åŠ¡åˆ†åˆ«å¤„ç†ç›¸åŒåª’ä½“ç»„\n")
    
    # Test 5: LRU cache limit (300 entries)
    print("æµ‹è¯• 5: LRUç¼“å­˜é™åˆ¶ï¼ˆ300æ¡è®°å½•ï¼‰")
    print("-" * 70)
    
    processed_media_groups.clear()
    processed_media_groups_order.clear()
    
    # Add 301 entries
    for i in range(301):
        key = f"user_task_group_{i}"
        register_processed_media_group(key)
    
    # The first key should have been evicted
    assert "user_task_group_0" not in processed_media_groups, "âŒ å¤±è´¥ï¼šæœ€æ—§çš„è®°å½•æœªè¢«æ¸…ç†"
    # The last key should still be there
    assert "user_task_group_300" in processed_media_groups, "âŒ å¤±è´¥ï¼šæœ€æ–°çš„è®°å½•è¢«é”™è¯¯æ¸…ç†"
    # Cache size should be exactly 300
    assert len(processed_media_groups) == 300, f"âŒ å¤±è´¥ï¼šç¼“å­˜å¤§å°ä¸º {len(processed_media_groups)}ï¼Œåº”è¯¥æ˜¯300"
    print(f"âœ… é€šè¿‡ï¼šLRUç¼“å­˜æ­£ç¡®ç»´æŒåœ¨300æ¡è®°å½•\n")
    
    # Test 6: Rapid-fire test (the original issue scenario)
    print("æµ‹è¯• 6: é«˜å¹¶å‘åœºæ™¯ï¼ˆæ¨¡æ‹ŸåŸå§‹é—®é¢˜æ—¥å¿—ï¼‰")
    print("-" * 70)
    print("åŸå§‹é—®é¢˜æ—¥å¿—:")
    print("  04:53:11,227 - ğŸ“¤ è½¬å‘æ¨¡å¼ï¼šå¼€å§‹å¤„ç†")
    print("  04:53:11,284 - ğŸ“¤ è½¬å‘æ¨¡å¼ï¼šå¼€å§‹å¤„ç†  // 57msåé‡å¤")
    print("  04:53:11,287 - ğŸ“¤ è½¬å‘æ¨¡å¼ï¼šå¼€å§‹å¤„ç†")
    print("  04:53:11,294 - ğŸ“¤ è½¬å‘æ¨¡å¼ï¼šå¼€å§‹å¤„ç†")
    print()
    print("ä¿®å¤åé¢„æœŸ:")
    print("  åªæœ‰ç¬¬ä¸€æ¡æ¶ˆæ¯ä¼šæ˜¾ç¤º 'ğŸ“¤ è½¬å‘æ¨¡å¼ï¼šå¼€å§‹å¤„ç†'")
    print("  åç»­æ¶ˆæ¯åº”æ˜¾ç¤º 'â­ï¸ è·³è¿‡ï¼šåª’ä½“ç»„å·²å¤„ç†'")
    print()
    
    processed_media_groups.clear()
    processed_media_groups_order.clear()
    
    media_group_id = "rapid_fire_test"
    forward_count = 0
    
    # Simulate 4 messages arriving within 67ms
    start_time = time.time()
    for i in range(1, 5):
        # Simulate timing from the logs (0ms, 57ms, 60ms, 67ms)
        if i > 1:
            time.sleep(0.001)  # Small delay to simulate near-simultaneous arrival
        
        if simulate_message_handler(user_id, watch_key, media_group_id, i):
            forward_count += 1
        print()
    
    elapsed = (time.time() - start_time) * 1000
    print(f"æ€»è€—æ—¶: {elapsed:.1f}ms")
    print(f"è½¬å‘æ¬¡æ•°: {forward_count}")
    print()
    
    assert forward_count == 1, f"âŒ å¤±è´¥ï¼šåœ¨é«˜å¹¶å‘åœºæ™¯ä¸‹è½¬å‘äº† {forward_count} æ¬¡"
    print("âœ… é€šè¿‡ï¼šé«˜å¹¶å‘åœºæ™¯ä¸‹åªè½¬å‘ä¸€æ¬¡\n")
    
    print("="*70)
    print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼åª’ä½“ç»„å»é‡ä¿®å¤ç”Ÿæ•ˆ")
    print("="*70)
    print("\nğŸ“‹ ä¿®å¤æ€»ç»“:")
    print("  âœ… åª’ä½“ç»„åœ¨é€šè¿‡è¿‡æ»¤è§„åˆ™åç«‹å³è¢«æ ‡è®°ä¸ºå·²å¤„ç†")
    print("  âœ… é˜²æ­¢äº†ç«æ€æ¡ä»¶å¯¼è‡´çš„é‡å¤è½¬å‘")
    print("  âœ… ä¸å½±å“å•æ¡æ¶ˆæ¯çš„æ­£å¸¸å¤„ç†")
    print("  âœ… ä¸å½±å“ä¸åŒåª’ä½“ç»„çš„ç‹¬ç«‹å¤„ç†")
    print("  âœ… LRUç¼“å­˜æ­£å¸¸å·¥ä½œï¼Œé˜²æ­¢å†…å­˜æ³„æ¼")


def test_without_fix():
    """
    Demonstrate the bug that existed before the fix.
    This shows what would happen if we marked the media group as processed
    AFTER forwarding instead of BEFORE.
    """
    print("\n" + "="*70)
    print("ğŸ› æ¼”ç¤ºä¿®å¤å‰çš„é—®é¢˜ï¼ˆæ ‡è®°å»¶è¿Ÿåˆ°è½¬å‘åï¼‰")
    print("="*70 + "\n")
    
    processed_media_groups.clear()
    processed_media_groups_order.clear()
    
    user_id = "12345"
    watch_key = "source|dest"
    media_group_id = "buggy_group"
    
    processed_count = 0
    
    for i in range(1, 5):
        media_group_key = f"{user_id}_{watch_key}_{media_group_id}"
        
        # Check if already processed
        if media_group_key in processed_media_groups:
            print(f"  æ¶ˆæ¯{i}: â­ï¸ è·³è¿‡ï¼šåª’ä½“ç»„å·²å¤„ç†")
            continue
        
        print(f"  æ¶ˆæ¯{i}: ğŸ¯ æ¶ˆæ¯é€šè¿‡æ‰€æœ‰è¿‡æ»¤è§„åˆ™ï¼Œå‡†å¤‡å¤„ç†")
        print(f"  æ¶ˆæ¯{i}: ğŸ“¤ è½¬å‘æ¨¡å¼ï¼šå¼€å§‹å¤„ç†")
        
        # BUG: Mark as processed AFTER forwarding (old behavior)
        # In reality, all 4 messages would pass the check before any of them finishes forwarding
        processed_count += 1
        
        # Simulate forwarding delay
        time.sleep(0.01)
        
        # Mark as processed (TOO LATE!)
        register_processed_media_group(media_group_key)
        print(f"  æ¶ˆæ¯{i}: âœ… æ¶ˆæ¯å·²è½¬å‘ï¼ˆç„¶åæ‰æ ‡è®°ä¸ºå·²å¤„ç†ï¼‰")
        print()
    
    print(f"ç»“æœï¼šåª’ä½“ç»„è¢«å¤„ç†äº† {processed_count} æ¬¡ âŒ")
    print(f"æœŸæœ›ï¼šåº”è¯¥åªå¤„ç† 1 æ¬¡")
    print("\nè¿™å°±æ˜¯ä¸ºä»€ä¹ˆéœ€è¦åœ¨è½¬å‘å‰ç«‹å³æ ‡è®°ï¼\n")


if __name__ == "__main__":
    # Run tests with the fix
    test_media_group_race_condition()
    
    # Demonstrate the problem without the fix
    test_without_fix()
