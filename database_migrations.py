"""
æ•°æ®åº“è¿ç§»è„šæœ¬
æ·»åŠ ç´¢å¼•å’Œä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½
"""
import sqlite3
import logging
from database import DATABASE_FILE

logger = logging.getLogger(__name__)


def create_indexes():
    """åˆ›å»ºæ•°æ®åº“ç´¢å¼•ä»¥æå‡æŸ¥è¯¢æ€§èƒ½"""
    conn = sqlite3.connect(DATABASE_FILE)
    cursor = conn.cursor()

    indexes = [
        # ==================== notes è¡¨ç´¢å¼• ====================
        # 1. å•åˆ—ç´¢å¼• - åŸºç¡€è¿‡æ»¤
        ("idx_notes_user_id", "CREATE INDEX IF NOT EXISTS idx_notes_user_id ON notes(user_id)"),
        ("idx_notes_source_chat_id", "CREATE INDEX IF NOT EXISTS idx_notes_source_chat_id ON notes(source_chat_id)"),
        ("idx_notes_timestamp", "CREATE INDEX IF NOT EXISTS idx_notes_timestamp ON notes(timestamp DESC)"),

        # 2. å¤åˆç´¢å¼• - æœ€å¸¸ç”¨æŸ¥è¯¢æ¨¡å¼ï¼ˆç”¨æˆ·+æ¥æº+æ—¶é—´æ’åºï¼‰
        ("idx_notes_user_source_time", "CREATE INDEX IF NOT EXISTS idx_notes_user_source_time ON notes(user_id, source_chat_id, timestamp DESC)"),

        # 3. éƒ¨åˆ†ç´¢å¼• - åª’ä½“ç»„å»é‡ï¼ˆä»…ç´¢å¼•éç©ºå€¼ï¼‰
        ("idx_notes_media_group_dedup", "CREATE INDEX IF NOT EXISTS idx_notes_media_group_dedup ON notes(user_id, source_chat_id, media_group_id) WHERE media_group_id IS NOT NULL"),

        # 4. éƒ¨åˆ†ç´¢å¼• - æ”¶è—è¿‡æ»¤ï¼ˆä»…ç´¢å¼•æ”¶è—é¡¹ï¼‰
        ("idx_notes_favorite", "CREATE INDEX IF NOT EXISTS idx_notes_favorite ON notes(user_id, is_favorite) WHERE is_favorite = 1"),

        # 5. éƒ¨åˆ†ç´¢å¼• - ç£åŠ›é“¾æ¥ï¼ˆä»…ç´¢å¼•éç©ºå€¼ï¼‰
        ("idx_notes_magnet_link", "CREATE INDEX IF NOT EXISTS idx_notes_magnet_link ON notes(magnet_link) WHERE magnet_link IS NOT NULL"),

        # 6. è¦†ç›–ç´¢å¼• - æœç´¢ä¼˜åŒ–
        ("idx_notes_search", "CREATE INDEX IF NOT EXISTS idx_notes_search ON notes(user_id, source_chat_id, message_text)"),

        # ==================== calibration_tasks è¡¨ç´¢å¼• ====================
        ("idx_calibration_status", "CREATE INDEX IF NOT EXISTS idx_calibration_status ON calibration_tasks(status, next_attempt)"),
        ("idx_calibration_note", "CREATE INDEX IF NOT EXISTS idx_calibration_note ON calibration_tasks(note_id)"),
        ("idx_calibration_created", "CREATE INDEX IF NOT EXISTS idx_calibration_created ON calibration_tasks(created_at DESC)"),
    ]

    created_count = 0
    for index_name, sql in indexes:
        try:
            cursor.execute(sql)
            logger.info(f"âœ… ç´¢å¼•å·²åˆ›å»º/ç¡®è®¤: {index_name}")
            created_count += 1
        except sqlite3.Error as e:
            logger.error(f"âŒ åˆ›å»ºç´¢å¼•å¤±è´¥ {index_name}: {e}")

    conn.commit()
    conn.close()

    logger.info(f"ğŸ“Š ç´¢å¼•åˆ›å»ºå®Œæˆ: {created_count}/{len(indexes)}")
    return created_count


def analyze_database():
    """åˆ†ææ•°æ®åº“ä»¥ä¼˜åŒ–æŸ¥è¯¢è®¡åˆ’"""
    conn = sqlite3.connect(DATABASE_FILE)
    cursor = conn.cursor()

    try:
        cursor.execute("ANALYZE")
        conn.commit()
        logger.info("âœ… æ•°æ®åº“åˆ†æå®Œæˆ")
    except sqlite3.Error as e:
        logger.error(f"âŒ æ•°æ®åº“åˆ†æå¤±è´¥: {e}")
    finally:
        conn.close()


def vacuum_database():
    """æ¸…ç†æ•°æ®åº“ç¢ç‰‡ï¼Œä¼˜åŒ–å­˜å‚¨"""
    conn = sqlite3.connect(DATABASE_FILE)
    cursor = conn.cursor()

    try:
        cursor.execute("VACUUM")
        logger.info("âœ… æ•°æ®åº“æ¸…ç†å®Œæˆ")
    except sqlite3.Error as e:
        logger.error(f"âŒ æ•°æ®åº“æ¸…ç†å¤±è´¥: {e}")
    finally:
        conn.close()


def get_database_stats():
    """è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
    conn = sqlite3.connect(DATABASE_FILE)
    cursor = conn.cursor()

    stats = {}

    try:
        # è¡¨è®°å½•æ•°
        cursor.execute("SELECT COUNT(*) FROM notes")
        stats['notes_count'] = cursor.fetchone()[0]

        cursor.execute("SELECT COUNT(*) FROM calibration_tasks")
        stats['calibration_tasks_count'] = cursor.fetchone()[0]

        cursor.execute("SELECT COUNT(*) FROM users")
        stats['users_count'] = cursor.fetchone()[0]

        # æ•°æ®åº“å¤§å°
        cursor.execute("SELECT page_count * page_size as size FROM pragma_page_count(), pragma_page_size()")
        stats['database_size_mb'] = round(cursor.fetchone()[0] / (1024 * 1024), 2)

        # ç´¢å¼•åˆ—è¡¨
        cursor.execute("SELECT name FROM sqlite_master WHERE type='index' AND name NOT LIKE 'sqlite_%'")
        stats['indexes'] = [row[0] for row in cursor.fetchall()]

        logger.info("ğŸ“Š æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯:")
        logger.info(f"   - ç¬”è®°æ•°é‡: {stats['notes_count']}")
        logger.info(f"   - æ ¡å‡†ä»»åŠ¡æ•°é‡: {stats['calibration_tasks_count']}")
        logger.info(f"   - ç”¨æˆ·æ•°é‡: {stats['users_count']}")
        logger.info(f"   - æ•°æ®åº“å¤§å°: {stats['database_size_mb']} MB")
        logger.info(f"   - ç´¢å¼•æ•°é‡: {len(stats['indexes'])}")

    except sqlite3.Error as e:
        logger.error(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
    finally:
        conn.close()

    return stats


def optimize_database():
    """æ‰§è¡Œå®Œæ•´çš„æ•°æ®åº“ä¼˜åŒ–"""
    logger.info("ğŸ”§ å¼€å§‹æ•°æ®åº“ä¼˜åŒ–...")

    # 1. åˆ›å»ºç´¢å¼•
    create_indexes()

    # 2. åˆ†ææ•°æ®åº“
    analyze_database()

    # 3. è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = get_database_stats()

    # 4. å¦‚æœæ•°æ®åº“è¾ƒå¤§ï¼Œæ‰§è¡ŒVACUUM
    if stats.get('database_size_mb', 0) > 100:
        logger.info("ğŸ’¾ æ•°æ®åº“è¾ƒå¤§ï¼Œæ‰§è¡Œæ¸…ç†...")
        vacuum_database()

    logger.info("âœ… æ•°æ®åº“ä¼˜åŒ–å®Œæˆï¼")
    return stats


def explain_query(query: str, params: tuple = ()) -> list:
    """åˆ†ææŸ¥è¯¢æ‰§è¡Œè®¡åˆ’

    Args:
        query: SQL æŸ¥è¯¢è¯­å¥
        params: æŸ¥è¯¢å‚æ•°

    Returns:
        æ‰§è¡Œè®¡åˆ’åˆ—è¡¨
    """
    conn = sqlite3.connect(DATABASE_FILE)
    cursor = conn.cursor()

    try:
        cursor.execute(f"EXPLAIN QUERY PLAN {query}", params)
        plan = cursor.fetchall()
        logger.info(f"ğŸ“‹ æŸ¥è¯¢æ‰§è¡Œè®¡åˆ’:")
        for row in plan:
            logger.info(f"   {row}")
        return plan
    except sqlite3.Error as e:
        logger.error(f"âŒ åˆ†ææŸ¥è¯¢å¤±è´¥: {e}")
        return []
    finally:
        conn.close()


def check_index_usage() -> dict:
    """æ£€æŸ¥ç´¢å¼•ä½¿ç”¨æƒ…å†µ

    Returns:
        ç´¢å¼•ä½¿ç”¨ç»Ÿè®¡
    """
    conn = sqlite3.connect(DATABASE_FILE)
    cursor = conn.cursor()

    result = {
        'indexes': [],
        'unused_indexes': [],
        'missing_indexes': []
    }

    try:
        # è·å–æ‰€æœ‰ç´¢å¼•
        cursor.execute("""
            SELECT name, tbl_name, sql
            FROM sqlite_master
            WHERE type='index' AND name NOT LIKE 'sqlite_%'
        """)
        result['indexes'] = [
            {'name': row[0], 'table': row[1], 'sql': row[2]}
            for row in cursor.fetchall()
        ]

        logger.info(f"ğŸ“Š æ•°æ®åº“ç´¢å¼•ç»Ÿè®¡:")
        logger.info(f"   - æ€»ç´¢å¼•æ•°: {len(result['indexes'])}")
        for idx in result['indexes']:
            logger.info(f"   - {idx['name']} ({idx['table']})")

    except sqlite3.Error as e:
        logger.error(f"âŒ æ£€æŸ¥ç´¢å¼•å¤±è´¥: {e}")
    finally:
        conn.close()

    return result


def benchmark_queries() -> dict:
    """åŸºå‡†æµ‹è¯•å¸¸ç”¨æŸ¥è¯¢

    Returns:
        æŸ¥è¯¢æ€§èƒ½ç»Ÿè®¡
    """
    import time

    conn = sqlite3.connect(DATABASE_FILE)
    cursor = conn.cursor()

    benchmarks = {}

    test_queries = [
        ("get_notes_by_user", "SELECT * FROM notes WHERE user_id = 1 ORDER BY timestamp DESC LIMIT 50"),
        ("get_notes_by_source", "SELECT * FROM notes WHERE user_id = 1 AND source_chat_id = '-1001234567890' ORDER BY timestamp DESC LIMIT 50"),
        ("get_notes_count", "SELECT COUNT(*) FROM notes WHERE user_id = 1"),
        ("get_favorites", "SELECT * FROM notes WHERE user_id = 1 AND is_favorite = 1 ORDER BY timestamp DESC LIMIT 50"),
        ("search_notes", "SELECT * FROM notes WHERE user_id = 1 AND message_text LIKE '%test%' ORDER BY timestamp DESC LIMIT 50"),
        ("get_pending_calibration", "SELECT * FROM calibration_tasks WHERE status IN ('pending', 'retrying') ORDER BY next_attempt ASC LIMIT 100"),
    ]

    logger.info("â±ï¸ å¼€å§‹æŸ¥è¯¢åŸºå‡†æµ‹è¯•...")

    for name, query in test_queries:
        try:
            start = time.perf_counter()
            cursor.execute(query)
            cursor.fetchall()
            elapsed = (time.perf_counter() - start) * 1000  # ms

            benchmarks[name] = {
                'time_ms': round(elapsed, 2),
                'status': 'fast' if elapsed < 10 else 'slow' if elapsed > 100 else 'normal'
            }
            logger.info(f"   - {name}: {elapsed:.2f}ms [{benchmarks[name]['status']}]")
        except sqlite3.Error as e:
            benchmarks[name] = {'error': str(e)}
            logger.error(f"   - {name}: é”™è¯¯ - {e}")

    conn.close()
    return benchmarks


if __name__ == '__main__':
    import sys

    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1:
        command = sys.argv[1]
        if command == 'optimize':
            optimize_database()
        elif command == 'indexes':
            create_indexes()
        elif command == 'analyze':
            analyze_database()
        elif command == 'vacuum':
            vacuum_database()
        elif command == 'stats':
            get_database_stats()
        elif command == 'benchmark':
            benchmark_queries()
        elif command == 'check':
            check_index_usage()
        else:
            print(f"æœªçŸ¥å‘½ä»¤: {command}")
            print("å¯ç”¨å‘½ä»¤: optimize, indexes, analyze, vacuum, stats, benchmark, check")
    else:
        # é»˜è®¤æ‰§è¡Œå®Œæ•´ä¼˜åŒ–
        optimize_database()
