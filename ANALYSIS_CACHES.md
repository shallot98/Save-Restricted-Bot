# Save-Restricted-Bot ç¼“å­˜å®ç°åˆ†ææŠ¥å‘Š

## æ‰§è¡Œæ‘˜è¦

æœ¬æŠ¥å‘Šå®¡æŸ¥äº† Save-Restricted-Bot ä¸­çš„æ‰€æœ‰ç¼“å­˜å®ç°ï¼Œè¯Šæ–­æ½œåœ¨çš„å†…å­˜ç“¶é¢ˆã€‚ç»è¿‡åˆ†æï¼Œå‘ç°äº† **3 ä¸ªä¸»è¦å†…å­˜é£é™©**ï¼Œå…¶ä¸­ 2 ä¸ªå·²åœ¨æœ€è¿‘ä¼˜åŒ–ä¸­å¾—åˆ°ç¼“è§£ï¼Œä½†ä»æœ‰ **3 ä¸ªä¸¥é‡çš„æœªå—é™ç¼“å­˜** éœ€è¦å…³æ³¨ã€‚

---

## 1. æ¶ˆæ¯å»é‡ç¼“å­˜ (`processed_messages`)

### ä½ç½®
- æ–‡ä»¶ï¼š`bot/utils/dedup.py`
- è¡Œæ•°ï¼š15
- ç±»å‹ï¼š`Dict[str, float]`

### ä»£ç å®ç°
```python
# Message deduplication cache
processed_messages: Dict[str, float] = {}
_message_lock = threading.Lock()

# æ¶ˆæ¯ç¼“å­˜æ¸…ç†é˜ˆå€¼ï¼ˆå½“ç¼“å­˜è¶…è¿‡æ­¤å¤§å°æ—¶è§¦å‘æ¸…ç†ï¼‰
MESSAGE_CACHE_MAX_SIZE = MESSAGE_CACHE_CLEANUP_THRESHOLD  # 500

def is_message_processed(message_id: int, chat_id: int) -> bool:
    """Check if a message has been recently processed (thread-safe)"""
    key = f"{chat_id}_{message_id}"
    
    with _message_lock:
        if key in processed_messages:
            timestamp = processed_messages[key]
            if time.time() - timestamp < MESSAGE_CACHE_TTL:  # 0.3ç§’
                return True
            # Expired, remove it
            del processed_messages[key]
        return False

def cleanup_old_messages():
    """Clean up expired message records (thread-safe)"""
    current_time = time.time()
    
    with _message_lock:
        # æ¸…ç†è¿‡æœŸæ¡ç›®
        expired_keys = [key for key, timestamp in processed_messages.items()
                        if current_time - timestamp > MESSAGE_CACHE_TTL]
        for key in expired_keys:
            del processed_messages[key]
        
        if expired_keys:
            logger.debug(f"ğŸ§¹ æ¶ˆæ¯ç¼“å­˜æ¸…ç†: ç§»é™¤{len(expired_keys)}ä¸ªè¿‡æœŸæ¡ç›®")
        
        # å¦‚æœç¼“å­˜ä»ç„¶è¿‡å¤§ï¼Œå¼ºåˆ¶æ¸…ç†æœ€æ—§çš„æ¡ç›®
        if len(processed_messages) > MESSAGE_CACHE_MAX_SIZE:
            # æŒ‰æ—¶é—´æˆ³æ’åºï¼Œåˆ é™¤æœ€æ—§çš„50%
            sorted_items = sorted(processed_messages.items(), key=lambda x: x[1])
            remove_count = len(sorted_items) // 2
            for key, _ in sorted_items[:remove_count]:
                del processed_messages[key]
            logger.info(f"ğŸ§¹ æ¶ˆæ¯ç¼“å­˜è¶…é™ï¼Œå¼ºåˆ¶æ¸…ç†{remove_count}ä¸ªæœ€æ—§æ¡ç›®")
```

### å½“å‰çŠ¶æ€
- **å¤§å°é™åˆ¶**ï¼šâœ… æœ‰ - `MESSAGE_CACHE_CLEANUP_THRESHOLD = 500`
- **TTL**ï¼šâœ… æœ‰ - `MESSAGE_CACHE_TTL = 0.3` ç§’
- **æ¸…ç†æœºåˆ¶**ï¼šâœ… æœ‰ - å®šæœŸæ¸…ç† + è¶…é™å¼ºåˆ¶æ¸…ç†
- **è§¦å‘æ—¶æœº**ï¼šæ¯ 60 ç§’ï¼ˆ`WORKER_STATS_INTERVAL`ï¼‰

### å†…å­˜ä¼°ç®—ï¼ˆ1000 æ¡æ¶ˆæ¯åœºæ™¯ï¼‰
- **é”®å¤§å°**ï¼š`"{chat_id}_{message_id}"` â‰ˆ 30 å­—ç¬¦ â‰ˆ 50 å­—èŠ‚
- **å€¼å¤§å°**ï¼š`float` æ—¶é—´æˆ³ â‰ˆ 8 å­—èŠ‚
- **å•æ¡è®°å½•**ï¼š~58 å­—èŠ‚
- **1000 æ¡æ¶ˆæ¯**ï¼š~58 KB
- **å®é™…æœ€å¤§å€¼**ï¼ˆ500 æ¡é™åˆ¶ï¼‰ï¼š~29 KB

### è¯„ä¼°
âœ… **çŠ¶æ€ï¼šå·²ä¼˜åŒ–è‰¯å¥½**
- æœ‰æ˜ç¡®çš„å¤§å°é™åˆ¶
- æœ‰åŒé‡æ¸…ç†æœºåˆ¶ï¼ˆTTL + è¶…é™å¼ºåˆ¶ï¼‰
- å†…å­˜å ç”¨å¯é¢„æµ‹ä¸”è¾ƒå°

---

## 2. åª’ä½“ç»„å»é‡ç¼“å­˜ (`processed_media_groups`)

### ä½ç½®
- æ–‡ä»¶ï¼š`bot/utils/dedup.py`
- è¡Œæ•°ï¼š20
- ç±»å‹ï¼š`OrderedDict[str, float]`

### ä»£ç å®ç°
```python
# Media group deduplication cache (LRU with OrderedDict for efficient cleanup)
processed_media_groups: OrderedDict[str, float] = OrderedDict()
_media_group_lock = threading.Lock()

# åª’ä½“ç»„å»é‡çš„æ—¶é—´çª—å£ï¼ˆç§’ï¼‰
MEDIA_GROUP_DEDUP_WINDOW = 2.0  # 2ç§’å†…çš„é‡å¤åª’ä½“ç»„ä¼šè¢«è¿‡æ»¤

def register_processed_media_group(key: str):
    """Register a media group as processed (thread-safe, LRU cache with timestamp)"""
    current_time = time.time()
    
    with _media_group_lock:
        # Move to end if exists (refresh LRU position)
        if key in processed_media_groups:
            processed_media_groups.move_to_end(key)
        
        # å­˜å‚¨å½“å‰æ—¶é—´æˆ³
        processed_media_groups[key] = current_time
        
        # LRU cleanup: remove oldest entries if cache exceeds limit
        if len(processed_media_groups) > MAX_MEDIA_GROUP_CACHE:  # 200
            # Remove oldest entries efficiently with loop protection
            removed_count = 0
            max_iterations = MEDIA_GROUP_CLEANUP_BATCH_SIZE  # 50
            
            for _ in range(max_iterations):
                if len(processed_media_groups) > MAX_MEDIA_GROUP_CACHE:
                    processed_media_groups.popitem(last=False)  # Remove oldest (FIFO)
                    removed_count += 1
                else:
                    break
            
            if removed_count > 0:
                logger.debug(f"ğŸ§¹ åª’ä½“ç»„ç¼“å­˜æ¸…ç†: ç§»é™¤æœ€æ—§çš„ {removed_count} ä¸ªæ¡ç›®")

def is_media_group_processed(key: str) -> bool:
    """Check if a media group has been processed within the dedup window"""
    current_time = time.time()
    
    with _media_group_lock:
        if key in processed_media_groups:
            timestamp = processed_media_groups[key]
            # æ£€æŸ¥æ˜¯å¦åœ¨å»é‡æ—¶é—´çª—å£å†…
            if current_time - timestamp < MEDIA_GROUP_DEDUP_WINDOW:
                return True
            else:
                # è¶…è¿‡æ—¶é—´çª—å£ï¼Œåˆ é™¤æ—§è®°å½•
                del processed_media_groups[key]
                return False
        return False
```

### å½“å‰çŠ¶æ€
- **å¤§å°é™åˆ¶**ï¼šâœ… æœ‰ - `MAX_MEDIA_GROUP_CACHE = 200`
- **TTL**ï¼šâœ… æœ‰ - `MEDIA_GROUP_DEDUP_WINDOW = 2.0` ç§’
- **æ¸…ç†æœºåˆ¶**ï¼šâœ… æœ‰ - LRU æœºåˆ¶ + æ—¶é—´çª—å£æ£€æŸ¥
- **æ•°æ®ç»“æ„**ï¼š`OrderedDict` - é«˜æ•ˆ LRU å®ç°

### å†…å­˜ä¼°ç®—ï¼ˆ200 æ¡åª’ä½“ç»„é™åˆ¶ï¼‰
- **é”®å¤§å°**ï¼š`"{user_id}_{watch_key}_{dest_chat_id}_{mode_suffix}_{media_group_id}"` â‰ˆ 100 å­—èŠ‚
- **å€¼å¤§å°**ï¼š`float` æ—¶é—´æˆ³ â‰ˆ 8 å­—èŠ‚
- **å•æ¡è®°å½•**ï¼š~108 å­—èŠ‚
- **æœ€å¤§å€¼**ï¼ˆ200 æ¡é™åˆ¶ï¼‰ï¼š~21.6 KB

### è¯„ä¼°
âœ… **çŠ¶æ€ï¼šå·²ä¼˜åŒ–è‰¯å¥½**
- ä½¿ç”¨ `OrderedDict` å®ç°é«˜æ•ˆ LRU
- æœ‰ä¸¥æ ¼çš„å¤§å°é™åˆ¶
- åŒé‡æ¸…ç†æœºåˆ¶ï¼ˆLRU + TTLï¼‰

---

## 3. Peer ç¼“å­˜ (`cached_dest_peers`)

### ä½ç½®
- æ–‡ä»¶ï¼š`bot/utils/peer.py`
- è¡Œæ•°ï¼š14
- ç±»å‹ï¼š`OrderedDict[str, float]`

### ä»£ç å®ç°
```python
# Cached destination peers (LRU cache with max size)
cached_dest_peers: OrderedDict[str, float] = OrderedDict()

# Failed peers that need delayed loading retry (LRU cache with max size)
failed_peers: OrderedDict[str, float] = OrderedDict()

# Retry cooldown in seconds (wait before retrying failed peer)
RETRY_COOLDOWN = 60

def mark_dest_cached(dest_id: str):
    """Mark destination peer as cached (LRU mechanism)"""
    # Add/update timestamp and move to end (most recently used)
    cached_dest_peers[dest_id] = time.time()
    cached_dest_peers.move_to_end(dest_id)
    
    # LRU cleanup: remove oldest entries if cache exceeds limit
    if len(cached_dest_peers) > MAX_CACHED_PEERS:  # 100
        oldest_peer = cached_dest_peers.popitem(last=False)
        logger.debug(f"ğŸ§¹ Peerç¼“å­˜å·²æ»¡ï¼Œç§»é™¤æœ€æ—§çš„: {oldest_peer[0]}")
    
    # Remove from failed peers if it was there
    if dest_id in failed_peers:
        del failed_peers[dest_id]

def mark_peer_failed(peer_id: str):
    """Mark peer as failed to cache (LRU mechanism)"""
    # Add/update timestamp and move to end
    failed_peers[peer_id] = time.time()
    failed_peers.move_to_end(peer_id)
    
    # LRU cleanup: remove oldest entries if cache exceeds limit
    if len(failed_peers) > MAX_FAILED_PEERS:  # 50
        oldest_failed = failed_peers.popitem(last=False)
        logger.debug(f"ğŸ§¹ å¤±è´¥Peerç¼“å­˜å·²æ»¡ï¼Œç§»é™¤æœ€æ—§çš„: {oldest_failed[0]}")
```

### å½“å‰çŠ¶æ€
- **å¤§å°é™åˆ¶**ï¼šâœ… æœ‰ - `MAX_CACHED_PEERS = 100` / `MAX_FAILED_PEERS = 50`
- **æ¸…ç†æœºåˆ¶**ï¼šâœ… æœ‰ - LRU æœºåˆ¶
- **æ•°æ®ç»“æ„**ï¼š`OrderedDict` - é«˜æ•ˆ LRU å®ç°

### å†…å­˜ä¼°ç®—
- **å•ä¸ª Peer ID**ï¼š~20 å­—èŠ‚ï¼ˆå­—ç¬¦ä¸²ï¼‰+ 8 å­—èŠ‚ï¼ˆæ—¶é—´æˆ³ï¼‰â‰ˆ 28 å­—èŠ‚
- **æœ€å¤§ç¼“å­˜**ï¼ˆ100 + 50ï¼‰ï¼š~4.2 KB

### è¯„ä¼°
âœ… **çŠ¶æ€ï¼šå·²ä¼˜åŒ–è‰¯å¥½**
- æ–°å¢çš„é™åˆ¶ï¼ˆä¹‹å‰æ— é™åˆ¶ï¼‰
- ä½¿ç”¨ LRU æœºåˆ¶è‡ªåŠ¨æ¸…ç†
- å†…å­˜å ç”¨å¾ˆå°

---

## 4. ç”¨æˆ·çŠ¶æ€ç¼“å­˜ (`user_states`)

### ä½ç½®
- æ–‡ä»¶ï¼š`bot/utils/status.py`
- è¡Œæ•°ï¼š7
- ç±»å‹ï¼š`Dict[str, Any]`

### ä»£ç å®ç°
```python
# User state storage
user_states: Dict[str, Any] = {}

def get_user_state(user_id: str) -> Dict[str, Any]:
    """Get user state"""
    return user_states.get(user_id, {})

def set_user_state(user_id: str, state: Dict[str, Any]):
    """Set user state"""
    user_states[user_id] = state

def clear_user_state(user_id: str):
    """Clear user state"""
    if user_id in user_states:
        del user_states[user_id]

def update_user_state(user_id: str, **kwargs):
    """Update user state with new values"""
    if user_id not in user_states:
        user_states[user_id] = {}
    user_states[user_id].update(kwargs)
```

### å½“å‰çŠ¶æ€
- **å¤§å°é™åˆ¶**ï¼šâŒ **æ— é™åˆ¶**
- **TTL**ï¼šâŒ **æ—  TTL**
- **æ¸…ç†æœºåˆ¶**ï¼šâš ï¸ ä»…åœ¨ç”¨æˆ·å®Œæˆäº¤äº’æ—¶æ‰‹åŠ¨æ¸…ç†
- **æ³„æ¼é£é™©**ï¼šâš ï¸ **ä¸­ç­‰** - ç”¨æˆ·æ”¾å¼ƒäº¤äº’æ—¶çŠ¶æ€æ°¸ä¸æ¸…ç†

### å†…å­˜ä¼°ç®—ï¼ˆ1000 ä¸ªæ´»è·ƒç”¨æˆ·åœºæ™¯ï¼‰
- **å•ä¸ªçŠ¶æ€**ï¼š~100 å­—èŠ‚ï¼ˆåŒ…å«ç”¨æˆ· IDã€æ“ä½œçŠ¶æ€ã€ä¸´æ—¶æ•°æ®ï¼‰
- **1000 ä¸ªç”¨æˆ·**ï¼š~100 KB
- **10000 ä¸ªé—å¼ƒçŠ¶æ€**ï¼š~1 MB

### è¯„ä¼°
âš ï¸ **çŠ¶æ€ï¼šéœ€è¦ä¼˜åŒ–**
- æ— è‡ªåŠ¨æ¸…ç†æœºåˆ¶
- ç”¨æˆ·æ”¾å¼ƒå¤šæ­¥æ“ä½œæ—¶çŠ¶æ€ä¼šæ°¸ä¹…ä¿ç•™
- é•¿æœŸè¿è¡Œå¯èƒ½ç§¯ç´¯å¤§é‡é—å¼ƒçŠ¶æ€

### å»ºè®®
1. æ·»åŠ  TTL æœºåˆ¶ï¼ˆå¦‚ 1 å°æ—¶ï¼‰
2. å®šæœŸæ¸…ç†è¿‡æœŸçŠ¶æ€
3. æ·»åŠ æœ€å¤§çŠ¶æ€æ•°é‡é™åˆ¶

---

## 5. æ¶ˆæ¯é˜Ÿåˆ— (`message_queue`)

### ä½ç½®
- æ–‡ä»¶ï¼š`bot/core/queue.py` / `main.py`
- è¡Œæ•°ï¼š34
- ç±»å‹ï¼š`queue.Queue`

### ä»£ç å®ç°
```python
def initialize_message_queue(acc):
    """åˆå§‹åŒ–æ¶ˆæ¯é˜Ÿåˆ—å’Œå·¥ä½œçº¿ç¨‹"""
    # åˆ›å»ºæ¶ˆæ¯é˜Ÿåˆ—
    message_queue = queue.Queue()  # âš ï¸ æ— å¤§å°é™åˆ¶
    
    # åˆ›å»ºæ¶ˆæ¯å·¥ä½œçº¿ç¨‹
    message_worker = MessageWorker(message_queue, acc, max_retries=MAX_RETRIES)
    worker_thread = threading.Thread(
        target=message_worker.run,
        daemon=True,
        name="MessageWorker"
    )
    
    # å¯åŠ¨å·¥ä½œçº¿ç¨‹
    worker_thread.start()
    
    return message_queue, message_worker
```

### å½“å‰çŠ¶æ€
- **å¤§å°é™åˆ¶**ï¼šâŒ **æ— é™åˆ¶**
- **æ¸…ç†æœºåˆ¶**ï¼šâœ… æ¶ˆæ¯å¤„ç†åè‡ªåŠ¨ç§»é™¤
- **å¢é•¿æ¨¡å¼**ï¼šåœ¨æ¶ˆæ¯çˆ†å‘æœŸé—´å¯èƒ½å¿«é€Ÿå¢é•¿
- **é£é™©åœºæ™¯**ï¼š
  - å¤§é‡æ¶ˆæ¯åŒæ—¶åˆ°è¾¾
  - å·¥ä½œçº¿ç¨‹å¤„ç†é€Ÿåº¦æ…¢ï¼ˆç½‘ç»œé—®é¢˜ã€API é™æµï¼‰
  - é‡è¯•æœºåˆ¶å¯¼è‡´æ¶ˆæ¯é‡æ–°å…¥é˜Ÿ

### å†…å­˜ä¼°ç®—
- **å•ä¸ª Message å¯¹è±¡**ï¼š~1-2 KBï¼ˆåŒ…å«æ¶ˆæ¯å…ƒæ•°æ®ã€æ–‡æœ¬ã€é…ç½®ï¼‰
- **1000 æ¡æ¶ˆæ¯ç§¯å‹**ï¼š~1-2 MB
- **10000 æ¡æ¶ˆæ¯ç§¯å‹**ï¼š~10-20 MB

### è¯„ä¼°
âš ï¸ **çŠ¶æ€ï¼šé«˜é£é™© - æ— é™åˆ¶å¢é•¿**
- åœ¨æ¶ˆæ¯çˆ†å‘æˆ–å¤„ç†å»¶è¿Ÿæ—¶å¯èƒ½å¿«é€Ÿå¢é•¿
- æ— é˜Ÿåˆ—å¤§å°é™åˆ¶
- æ— è¿‡è½½ä¿æŠ¤æœºåˆ¶

### å»ºè®®
1. æ·»åŠ é˜Ÿåˆ—æœ€å¤§å¤§å°é™åˆ¶ï¼ˆå¦‚ `maxsize=10000`ï¼‰
2. å½“é˜Ÿåˆ—æ¥è¿‘æ»¡æ—¶è®°å½•è­¦å‘Š
3. è€ƒè™‘åœ¨æç«¯è¿‡è½½æ—¶æ‹’ç»æˆ–è·³è¿‡æ¶ˆæ¯
4. æ·»åŠ é˜Ÿåˆ—å¤§å°ç›‘æ§æŒ‡æ ‡

---

## 6. Pyrogram Session Peer ç¼“å­˜ï¼ˆæœ€ä¸¥é‡ï¼‰

### ä½ç½®
- æ–‡ä»¶ï¼š`session-storage/myacc.session`ï¼ˆSQLite æ•°æ®åº“ï¼‰
- ç®¡ç†ï¼šPyrogram å†…éƒ¨
- åˆå§‹åŒ–ï¼š`bot/core/client.py` è¡Œ 47-54

### ä»£ç å®ç°
```python
# å…ˆå°è¯•ä½¿ç”¨å·²æœ‰çš„ session æ–‡ä»¶ï¼ˆåŒ…å« Peer ç¼“å­˜ï¼‰
os.makedirs("session-storage", exist_ok=True)
session_file = "session-storage/myacc"

if os.path.exists(f"{session_file}.session"):
    logger.info("ğŸ“‚ å‘ç°å·²æœ‰ Session æ–‡ä»¶ï¼Œå°†ä¿ç•™ Peer ç¼“å­˜")
    acc = Client(session_file, api_id=api_id, api_hash=api_hash)
else:
    logger.info("ğŸ“ é¦–æ¬¡å¯åŠ¨ï¼Œä½¿ç”¨ Session String åˆ›å»º Session æ–‡ä»¶")
    acc = Client(session_file, api_id=api_id, api_hash=api_hash, session_string=ss)

# å¯åŠ¨Userå®¢æˆ·ç«¯
acc.start()
```

### Session æ–‡ä»¶ç»“æ„ï¼ˆPyrogram å†…éƒ¨ï¼‰
Pyrogram ä½¿ç”¨ SQLite æ•°æ®åº“å­˜å‚¨ï¼š
- **peers è¡¨**ï¼šå­˜å‚¨æ‰€æœ‰é‡åˆ°çš„ peerï¼ˆç”¨æˆ·ã€ç¾¤ç»„ã€é¢‘é“ï¼‰
  - user_id, access_hash, username, phone_number
  - chat_id, title, username
  - channel_id, title, username
- **ç‰ˆæœ¬ä¿¡æ¯**
- **ä¼šè¯å¯†é’¥**

### å½“å‰çŠ¶æ€
- **å¤§å°é™åˆ¶**ï¼šâŒ **æ— é™åˆ¶**
- **æ¸…ç†æœºåˆ¶**ï¼šâŒ **å®Œå…¨æ²¡æœ‰**
- **å¢é•¿æ¨¡å¼**ï¼š
  - æ¯æ¬¡é‡åˆ°æ–° peer å°±æ·»åŠ 
  - æ°¸ä¸åˆ é™¤æ—§ peer
  - éšæ—¶é—´çº¿æ€§å¢é•¿
- **æ³„æ¼é£é™©**ï¼šğŸ”´ **ä¸¥é‡** - é•¿æœŸè¿è¡Œå¿…å®šå¢é•¿

### å†…å­˜ä¼°ç®—
- **å•ä¸ª Peer è®°å½•**ï¼š~200-500 å­—èŠ‚ï¼ˆåŒ…å« SQLite å¼€é”€ï¼‰
- **1000 ä¸ª Peer**ï¼š~1-5 MBï¼ˆç£ç›˜ï¼‰
- **10000 ä¸ª Peer**ï¼š~10-50 MBï¼ˆç£ç›˜ï¼‰
- **é•¿æœŸè¿è¡Œï¼ˆæ•°æœˆï¼‰**ï¼šå¯èƒ½è¾¾åˆ° 100+ MB

### å®é™…å½±å“
- **ç£ç›˜ç©ºé—´**ï¼šSession æ–‡ä»¶æŒç»­å¢é•¿
- **å¯åŠ¨æ—¶é—´**ï¼šPyrogram åŠ è½½ session æ—¶é—´å¢åŠ 
- **å†…å­˜å ç”¨**ï¼šPyrogram å°†éƒ¨åˆ† peer æ•°æ®åŠ è½½åˆ°å†…å­˜

### è¯„ä¼°
ğŸ”´ **çŠ¶æ€ï¼šä¸¥é‡é£é™© - æ— é™åˆ¶é•¿æœŸå¢é•¿**
- Pyrogram ä¸æä¾›è‡ªåŠ¨æ¸…ç†æœºåˆ¶
- Bot é•¿æœŸè¿è¡Œå session æ–‡ä»¶å¿…ç„¶è†¨èƒ€
- æ˜¯æœ€ä¸¥é‡çš„å†…å­˜/ç£ç›˜æ³„æ¼æº

### å»ºè®®
1. **å®šæœŸé‡å»º Session æ–‡ä»¶**ï¼ˆæ¨èï¼‰
   ```python
   # å®šæœŸï¼ˆå¦‚æ¯å‘¨ï¼‰åˆ é™¤ session æ–‡ä»¶ï¼Œè®© Pyrogram é‡å»º
   # å¤‡ä»½ â†’ åˆ é™¤ â†’ é‡å¯ â†’ é‡å»ºï¼ˆåªä¿ç•™æ´»è·ƒ peerï¼‰
   ```

2. **æ‰‹åŠ¨æ¸…ç† Session æ•°æ®åº“**ï¼ˆé«˜çº§ï¼‰
   ```python
   # ä½¿ç”¨ SQLite ç›´æ¥æ“ä½œ session æ–‡ä»¶
   # åˆ é™¤æ—§çš„/ä¸æ´»è·ƒçš„ peer è®°å½•
   # é£é™©ï¼šå¯èƒ½å½±å“ Pyrogram æ­£å¸¸è¿è¡Œ
   ```

3. **ç›‘æ§ Session æ–‡ä»¶å¤§å°**
   ```python
   # å®šæœŸæ£€æŸ¥æ–‡ä»¶å¤§å°ï¼Œè¶…è¿‡é˜ˆå€¼æ—¶å‘Šè­¦
   session_size = os.path.getsize("session-storage/myacc.session")
   if session_size > 50 * 1024 * 1024:  # 50MB
       logger.warning(f"âš ï¸ Session æ–‡ä»¶è¿‡å¤§: {session_size / 1024 / 1024:.1f} MB")
   ```

4. **ä½¿ç”¨å†…å­˜æ¨¡å¼**ï¼ˆä¸æ¨èç”Ÿäº§ç¯å¢ƒï¼‰
   ```python
   # ä½¿ç”¨ ":memory:" ä½œä¸º sessionï¼Œä½†ä¼šå¤±å»æŒä¹…åŒ–
   # ä¸é€‚åˆç”Ÿäº§ç¯å¢ƒï¼Œæ¯æ¬¡é‡å¯éœ€é‡æ–°ç¼“å­˜
   ```

---

## 7. ç›‘æ§æºé›†åˆ (`_monitored_sources`)

### ä½ç½®
- æ–‡ä»¶ï¼š`config.py`
- è¡Œæ•°ï¼š25
- ç±»å‹ï¼š`Set[str]`

### ä»£ç å®ç°
```python
# Global state
_monitored_sources: Set[str] = set()

def build_monitored_sources() -> Set[str]:
    """Build a set of all monitored source chat IDs from watch config"""
    watch_config = load_watch_config()
    sources = set()
    
    for user_id, watches in watch_config.items():
        for watch_key, watch_data in watches.items():
            if isinstance(watch_data, dict):
                source = watch_data.get('source')
            else:
                source = watch_key
            
            if source and source != 'me':
                sources.add(str(source))
    
    return sources

def reload_monitored_sources():
    """Reload the monitored sources set (call after config changes)"""
    global _monitored_sources
    _monitored_sources = build_monitored_sources()
    logger.info(f"ğŸ”„ ç›‘æ§æºå·²æ›´æ–°: {_monitored_sources if _monitored_sources else 'æ— '}")
```

### å½“å‰çŠ¶æ€
- **å¤§å°é™åˆ¶**ï¼šå–å†³äºé…ç½®ï¼ˆé€šå¸¸å¾ˆå°ï¼‰
- **æ¸…ç†æœºåˆ¶**ï¼šé…ç½®æ›´æ–°æ—¶é‡æ–°åŠ è½½
- **å†…å­˜ä¼°ç®—**ï¼šé€šå¸¸ < 1 KBï¼ˆå‡ åä¸ªæºï¼‰

### è¯„ä¼°
âœ… **çŠ¶æ€ï¼šæ— é£é™©**
- å¤§å°ç”±ç”¨æˆ·é…ç½®å†³å®šï¼Œé€šå¸¸å¾ˆå°
- ä¸ä¼šæ— é™å¢é•¿

---

## ä¸‰å¤§å†…å­˜ç“¶é¢ˆæ’å

### ğŸ”´ 1. Pyrogram Session Peer ç¼“å­˜ï¼ˆæœ€ä¸¥é‡ï¼‰
**é£é™©ç­‰çº§ï¼šä¸¥é‡ | å¢é•¿æ¨¡å¼ï¼šé•¿æœŸçº¿æ€§å¢é•¿ | æ¸…ç†ï¼šæ— **

- **é—®é¢˜**ï¼šPyrogram å†…éƒ¨ SQLite æ•°æ®åº“ï¼Œæ°¸ä¸æ¸…ç†æ—§ peer
- **å½±å“**ï¼šç£ç›˜ + å†…å­˜ï¼Œé•¿æœŸè¿è¡Œåå¿…å®šè†¨èƒ€ï¼ˆæ•°æœˆå¯è¾¾ 100+ MBï¼‰
- **ç´§æ€¥åº¦**ï¼šğŸ”´ é«˜ - é•¿æœŸè¿è¡Œå¿…ç°
- **ä¼˜å…ˆçº§**ï¼š**æœ€é«˜**

**ä¼°ç®—ï¼š**
- 1 ä¸ªæœˆè¿è¡Œï¼š~5-20 MB
- 6 ä¸ªæœˆè¿è¡Œï¼š~30-100 MB
- 1 å¹´è¿è¡Œï¼š~60-200 MB

### âš ï¸ 2. æ¶ˆæ¯é˜Ÿåˆ— (`message_queue`)ï¼ˆé«˜é£é™©ï¼‰
**é£é™©ç­‰çº§ï¼šé«˜ | å¢é•¿æ¨¡å¼ï¼šçˆ†å‘æ€§å¢é•¿ | æ¸…ç†ï¼šå¤„ç†åè‡ªåŠ¨ç§»é™¤**

- **é—®é¢˜**ï¼šæ— å¤§å°é™åˆ¶ï¼Œæ¶ˆæ¯çˆ†å‘æ—¶å¯èƒ½ç§¯å‹
- **å½±å“**ï¼šä»…å†…å­˜ï¼ŒçŸ­æœŸå†…å¯èƒ½å¿«é€Ÿå¢é•¿
- **è§¦å‘æ¡ä»¶**ï¼šæ¶ˆæ¯çˆ†å‘ã€ç½‘ç»œå»¶è¿Ÿã€API é™æµ
- **ç´§æ€¥åº¦**ï¼šâš ï¸ ä¸­ - ç‰¹å®šåœºæ™¯è§¦å‘
- **ä¼˜å…ˆçº§**ï¼š**æ¬¡é«˜**

**ä¼°ç®—ï¼š**
- æ­£å¸¸è¿è¡Œï¼š< 1 MB
- æ¶ˆæ¯çˆ†å‘ï¼ˆ1000 æ¡ç§¯å‹ï¼‰ï¼š~1-2 MB
- æç«¯çˆ†å‘ï¼ˆ10000 æ¡ç§¯å‹ï¼‰ï¼š~10-20 MB

### âš ï¸ 3. ç”¨æˆ·çŠ¶æ€ç¼“å­˜ (`user_states`)ï¼ˆä¸­ç­‰é£é™©ï¼‰
**é£é™©ç­‰çº§ï¼šä¸­ç­‰ | å¢é•¿æ¨¡å¼ï¼šç¼“æ…¢ç§¯ç´¯ | æ¸…ç†ï¼šæ‰‹åŠ¨æ¸…ç†**

- **é—®é¢˜**ï¼šæ—  TTLï¼Œç”¨æˆ·æ”¾å¼ƒäº¤äº’æ—¶çŠ¶æ€æ°¸ä¸æ¸…ç†
- **å½±å“**ï¼šä»…å†…å­˜ï¼Œç¼“æ…¢ç§¯ç´¯
- **è§¦å‘æ¡ä»¶**ï¼šç”¨æˆ·é¢‘ç¹å¼€å§‹ä½†ä¸å®Œæˆå¤šæ­¥æ“ä½œ
- **ç´§æ€¥åº¦**ï¼šâš ï¸ ä½ - ç¼“æ…¢ç§¯ç´¯
- **ä¼˜å…ˆçº§**ï¼š**ç¬¬ä¸‰**

**ä¼°ç®—ï¼š**
- æ­£å¸¸è¿è¡Œï¼ˆ100 ä¸ªæ´»è·ƒç”¨æˆ·ï¼‰ï¼š~10 KB
- 1000 ä¸ªé—å¼ƒçŠ¶æ€ï¼š~100 KB
- 10000 ä¸ªé—å¼ƒçŠ¶æ€ï¼š~1 MB

---

## å·²ä¼˜åŒ–çš„ç¼“å­˜ï¼ˆè‰¯å¥½å®è·µï¼‰âœ…

ä»¥ä¸‹ç¼“å­˜å·²ç»å®ç°äº†è‰¯å¥½çš„å¤§å°é™åˆ¶å’Œæ¸…ç†æœºåˆ¶ï¼š

1. âœ… **æ¶ˆæ¯å»é‡ç¼“å­˜** - TTL + å¤§å°é™åˆ¶ + å¼ºåˆ¶æ¸…ç†
2. âœ… **åª’ä½“ç»„å»é‡ç¼“å­˜** - LRU + å¤§å°é™åˆ¶ + TTL
3. âœ… **Peer ç¼“å­˜** - LRU + å¤§å°é™åˆ¶
4. âœ… **å¤±è´¥ Peer ç¼“å­˜** - LRU + å¤§å°é™åˆ¶
5. âœ… **ç›‘æ§æºé›†åˆ** - é…ç½®é©±åŠ¨ï¼Œè‡ªåŠ¨åŒæ­¥

è¿™äº›ä¼˜åŒ–å±•ç¤ºäº†è‰¯å¥½çš„ç¼“å­˜ç®¡ç†å®è·µï¼Œå¯ä½œä¸ºå…¶ä»–ç¼“å­˜ä¼˜åŒ–çš„å‚è€ƒæ¨¡æ¿ã€‚

---

## åˆæ­¥ä¼˜åŒ–å»ºè®®

### ä¼˜å…ˆçº§ 1ï¼šPyrogram Session Peer ç¼“å­˜ï¼ˆç«‹å³å¤„ç†ï¼‰

#### æ–¹æ¡ˆ Aï¼šå®šæœŸé‡å»º Session æ–‡ä»¶ï¼ˆæ¨èï¼‰
```python
# æ–°å¢: bot/maintenance/session_cleaner.py
import os
import shutil
from datetime import datetime

def cleanup_session_file(session_path, backup_dir="session-backups"):
    """æ¸…ç† Session æ–‡ä»¶"""
    if not os.path.exists(f"{session_path}.session"):
        return
    
    # æ£€æŸ¥æ–‡ä»¶å¤§å°
    file_size = os.path.getsize(f"{session_path}.session") / (1024 * 1024)  # MB
    
    if file_size > 50:  # è¶…è¿‡ 50MB
        logger.warning(f"âš ï¸ Session æ–‡ä»¶è¿‡å¤§: {file_size:.1f} MBï¼Œå»ºè®®æ¸…ç†")
        
        # å¤‡ä»½
        os.makedirs(backup_dir, exist_ok=True)
        backup_path = f"{backup_dir}/myacc_{datetime.now().strftime('%Y%m%d_%H%M%S')}.session"
        shutil.copy(f"{session_path}.session", backup_path)
        logger.info(f"âœ… å·²å¤‡ä»½ Session åˆ°: {backup_path}")
        
        # åˆ é™¤ï¼ˆé‡å¯å Pyrogram ä¼šé‡å»ºï¼‰
        os.remove(f"{session_path}.session")
        logger.info("ğŸ—‘ï¸ å·²åˆ é™¤æ—§ Session æ–‡ä»¶ï¼Œé‡å¯åå°†é‡å»º")
```

#### æ–¹æ¡ˆ Bï¼šç›‘æ§ + å‘Šè­¦
```python
# åœ¨ main.py å¯åŠ¨æ—¶æ·»åŠ 
session_path = "session-storage/myacc.session"
if os.path.exists(session_path):
    size_mb = os.path.getsize(session_path) / (1024 * 1024)
    logger.info(f"ğŸ“Š Session æ–‡ä»¶å¤§å°: {size_mb:.1f} MB")
    if size_mb > 50:
        logger.warning(f"âš ï¸ Session æ–‡ä»¶è¿‡å¤§ï¼Œå»ºè®®æ¸…ç†")
```

### ä¼˜å…ˆçº§ 2ï¼šæ¶ˆæ¯é˜Ÿåˆ—å¤§å°é™åˆ¶

```python
# ä¿®æ”¹: bot/core/queue.py
def initialize_message_queue(acc):
    """åˆå§‹åŒ–æ¶ˆæ¯é˜Ÿåˆ—å’Œå·¥ä½œçº¿ç¨‹"""
    # åˆ›å»ºæœ‰é™å¤§å°çš„æ¶ˆæ¯é˜Ÿåˆ—
    MAX_QUEUE_SIZE = 10000  # æœ€å¤šç§¯å‹ 10000 æ¡æ¶ˆæ¯
    message_queue = queue.Queue(maxsize=MAX_QUEUE_SIZE)
    
    # ... å…¶ä½™ä»£ç ä¸å˜
```

```python
# ä¿®æ”¹: å…¥é˜Ÿé€»è¾‘ï¼ˆéœ€è¦å¤„ç†é˜Ÿåˆ—æ»¡çš„æƒ…å†µï¼‰
try:
    message_queue.put(msg_obj, block=False)  # éé˜»å¡
except queue.Full:
    logger.warning("âš ï¸ æ¶ˆæ¯é˜Ÿåˆ—å·²æ»¡ï¼Œè·³è¿‡æ­¤æ¶ˆæ¯ï¼ˆè¿‡è½½ä¿æŠ¤ï¼‰")
    # å¯é€‰ï¼šå¢åŠ ä¸¢å¼ƒè®¡æ•°å™¨
```

### ä¼˜å…ˆçº§ 3ï¼šç”¨æˆ·çŠ¶æ€ TTL æ¸…ç†

```python
# ä¿®æ”¹: bot/utils/status.py
import time
from typing import Dict, Any

# User state storage with timestamps
user_states: Dict[str, Dict[str, Any]] = {}
USER_STATE_TTL = 3600  # 1å°æ—¶

def set_user_state(user_id: str, state: Dict[str, Any]):
    """Set user state with timestamp"""
    user_states[user_id] = {
        'data': state,
        'timestamp': time.time()
    }

def get_user_state(user_id: str) -> Dict[str, Any]:
    """Get user state (auto-cleanup expired)"""
    if user_id in user_states:
        state_obj = user_states[user_id]
        if time.time() - state_obj['timestamp'] < USER_STATE_TTL:
            return state_obj['data']
        else:
            # è¿‡æœŸï¼Œæ¸…ç†
            del user_states[user_id]
    return {}

def cleanup_expired_states():
    """Clean up expired user states (call periodically)"""
    current_time = time.time()
    expired_users = [
        uid for uid, state_obj in user_states.items()
        if current_time - state_obj['timestamp'] > USER_STATE_TTL
    ]
    for uid in expired_users:
        del user_states[uid]
    if expired_users:
        logger.debug(f"ğŸ§¹ æ¸…ç†äº† {len(expired_users)} ä¸ªè¿‡æœŸç”¨æˆ·çŠ¶æ€")
```

---

## å†…å­˜ä½¿ç”¨æ€»ç»“ï¼ˆ1000 æ¡æ¶ˆæ¯åœºæ™¯ï¼‰

| ç¼“å­˜åç§° | å½“å‰å¤§å° | æ˜¯å¦æœ‰é™åˆ¶ | æ¸…ç†æœºåˆ¶ | é£é™©ç­‰çº§ |
|---------|---------|-----------|---------|---------|
| æ¶ˆæ¯å»é‡ç¼“å­˜ | ~29 KB | âœ… 500æ¡ | âœ… TTL + å¼ºåˆ¶ | âœ… ä½ |
| åª’ä½“ç»„ç¼“å­˜ | ~21.6 KB | âœ… 200æ¡ | âœ… LRU + TTL | âœ… ä½ |
| Peer ç¼“å­˜ | ~4.2 KB | âœ… 150æ¡ | âœ… LRU | âœ… ä½ |
| ç”¨æˆ·çŠ¶æ€ | ~100 KB | âŒ æ—  | âš ï¸ æ‰‹åŠ¨ | âš ï¸ ä¸­ |
| æ¶ˆæ¯é˜Ÿåˆ— | ~1-2 MB | âŒ æ—  | âš ï¸ å¤„ç†å | âš ï¸ é«˜ |
| Session Peer | ~10-50 MB | âŒ æ—  | âŒ æ—  | ğŸ”´ ä¸¥é‡ |
| ç›‘æ§æº | ~1 KB | âœ… é…ç½®é™åˆ¶ | âœ… è‡ªåŠ¨ | âœ… ä½ |
| **æ€»è®¡ï¼ˆä¼°ç®—ï¼‰** | **~11-53 MB** | - | - | - |

**æ³¨æ„**ï¼šSession Peer ç¼“å­˜ä¼šéšæ—¶é—´çº¿æ€§å¢é•¿ï¼Œæ˜¯å”¯ä¸€çš„é•¿æœŸæ³„æ¼æºã€‚

---

## ç›‘æ§å»ºè®®

### 1. æ·»åŠ ç¼“å­˜ç»Ÿè®¡ç«¯ç‚¹
```python
# åœ¨ app.py æ·»åŠ ç›‘æ§è·¯ç”±
@app.route('/api/cache-stats')
def cache_stats():
    """è¿”å›æ‰€æœ‰ç¼“å­˜çš„ç»Ÿè®¡ä¿¡æ¯"""
    from bot.utils.dedup import get_cache_stats
    from bot.utils.peer import cached_dest_peers, failed_peers
    from bot.utils.status import user_states
    import os
    
    stats = {
        'message_cache': get_cache_stats(),
        'peer_cache': {
            'cached_peers': len(cached_dest_peers),
            'failed_peers': len(failed_peers),
        },
        'user_states': len(user_states),
        'queue_size': message_queue.qsize() if message_queue else 0,
        'session_file_mb': os.path.getsize("session-storage/myacc.session") / (1024 * 1024)
            if os.path.exists("session-storage/myacc.session") else 0
    }
    return jsonify(stats)
```

### 2. å®šæœŸæ—¥å¿—è®°å½•
```python
# åœ¨ MessageWorker.run() ä¸­æ·»åŠ 
if time.time() - self.last_stats_time > WORKER_STATS_INTERVAL:
    # ç°æœ‰ç»Ÿè®¡
    logger.info(f"ğŸ“Š é˜Ÿåˆ—ç»Ÿè®¡: ...")
    
    # æ–°å¢ï¼šç¼“å­˜ç»Ÿè®¡
    logger.info(f"ğŸ“Š ç¼“å­˜ç»Ÿè®¡: "
                f"æ¶ˆæ¯={len(processed_messages)}, "
                f"åª’ä½“ç»„={len(processed_media_groups)}, "
                f"Peer={len(cached_dest_peers)}, "
                f"ç”¨æˆ·çŠ¶æ€={len(user_states)}")
```

---

## ç»“è®º

Save-Restricted-Bot çš„ç¼“å­˜å®ç°**æ•´ä½“è‰¯å¥½**ï¼Œå¤šæ•°ç¼“å­˜å·²å®ç°äº†æœ‰æ•ˆçš„å¤§å°é™åˆ¶å’Œæ¸…ç†æœºåˆ¶ã€‚ä½†å­˜åœ¨ **3 ä¸ªå…³é”®é—®é¢˜**ï¼š

1. ğŸ”´ **Pyrogram Session Peer ç¼“å­˜** - ä¸¥é‡é•¿æœŸæ³„æ¼ï¼Œéœ€ç«‹å³å¤„ç†
2. âš ï¸ **æ¶ˆæ¯é˜Ÿåˆ—æ— é™åˆ¶** - çˆ†å‘æœŸé—´é£é™©ï¼Œéœ€æ·»åŠ é™åˆ¶
3. âš ï¸ **ç”¨æˆ·çŠ¶æ€æ— æ¸…ç†** - ç¼“æ…¢ç§¯ç´¯ï¼Œéœ€æ·»åŠ  TTL

å»ºè®®æŒ‰ä¼˜å…ˆçº§ä¾æ¬¡å¤„ç†è¿™äº›é—®é¢˜ï¼Œä»¥ç¡®ä¿ Bot é•¿æœŸç¨³å®šè¿è¡Œã€‚

---

**ç”Ÿæˆæ—¶é—´**: 2024
**åˆ†æç‰ˆæœ¬**: v1.0
**ä¸‹ä¸€æ­¥**: æ ¹æ®ä¼˜å…ˆçº§å®æ–½ä¼˜åŒ–å»ºè®®
