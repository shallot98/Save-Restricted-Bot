"""
è‡ªåŠ¨è½¬å‘å¤„ç†å™¨æ¨¡å—
èŒè´£ï¼šå¤„ç†é¢‘é“/ç¾¤ç»„æ¶ˆæ¯çš„è‡ªåŠ¨è½¬å‘

Architecture: Uses new layered architecture
- src/core/container for service access
- src/infrastructure/cache for message deduplication
"""
import queue
import pyrogram
from pyrogram import filters
from bot.utils.logger import get_logger
from bot.utils import is_message_processed, mark_message_processed, cleanup_old_messages
from bot.utils.dedup import is_media_group_processed, register_processed_media_group, processed_messages
from bot.workers import Message

# New architecture imports
from src.core.container import get_watch_service
from src.infrastructure.cache import get_cache

# Legacy imports (for backward compatibility during migration)
from constants import MESSAGE_CACHE_CLEANUP_THRESHOLD

logger = get_logger(__name__)

# Use new cache for monitored sources
_monitored_sources_cache = get_cache()


def create_auto_forward_handler(acc, message_queue):
    """
    åˆ›å»ºè‡ªåŠ¨è½¬å‘å¤„ç†å™¨

    Args:
        acc: Userå®¢æˆ·ç«¯å®ä¾‹
        message_queue: æ¶ˆæ¯é˜Ÿåˆ—å®ä¾‹

    Returns:
        function: è‡ªåŠ¨è½¬å‘å¤„ç†å™¨å‡½æ•°
    """

    @acc.on_message((filters.channel | filters.group | filters.private) & (filters.incoming | filters.outgoing))
    def auto_forward(client: pyrogram.client.Client, message: pyrogram.types.messages_and_media.message.Message):
        """å¤„ç†é¢‘é“/ç¾¤ç»„/ç§èŠæ¶ˆæ¯ï¼ŒåŒ…æ‹¬è½¬å‘çš„æ¶ˆæ¯"""
        try:
            try:
                from src.infrastructure.monitoring.performance.business_metrics import get_business_metrics

                metrics = get_business_metrics()
            except Exception:
                metrics = None

            # æ·»åŠ è°ƒè¯•æ—¥å¿—ï¼šè®°å½•æ‰€æœ‰æ¥æ”¶åˆ°çš„æ¶ˆæ¯
            logger.info(f"ğŸ”” æ”¶åˆ°æ¶ˆæ¯: chat_id={message.chat.id if message and message.chat else 'Unknown'}, message_id={message.id if message else 'Unknown'}")

            # éªŒè¯æ¶ˆæ¯å¯¹è±¡å’Œå±æ€§
            if not message or not hasattr(message, 'chat') or not message.chat:
                logger.debug("è·³è¿‡ï¼šæ¶ˆæ¯å¯¹è±¡æ— æ•ˆæˆ–ç¼ºå°‘ chat å±æ€§")
                return

            # éªŒè¯chat ID
            if not hasattr(message.chat, 'id') or message.chat.id is None:
                logger.debug("è·³è¿‡ï¼šæ¶ˆæ¯ç¼ºå°‘æœ‰æ•ˆçš„ chat ID")
                return

            # æ£€æŸ¥é‡å¤æ¶ˆæ¯
            if not hasattr(message, 'id') or message.id is None:
                logger.debug("è·³è¿‡ï¼šæ¶ˆæ¯ç¼ºå°‘æœ‰æ•ˆçš„ message ID")
                return

            if is_message_processed(message.id, message.chat.id):
                logger.debug(f"â­ï¸ è·³è¿‡å·²å¤„ç†çš„æ¶ˆæ¯: chat_id={message.chat.id}, message_id={message.id}")
                return

            # ç«‹å³æ ‡è®°ä¸ºå·²å¤„ç†ï¼Œé˜²æ­¢é‡å¤å¤„ç†
            mark_message_processed(message.id, message.chat.id)

            # å®šæœŸæ¸…ç†æ—§æ¶ˆæ¯è®°å½•
            if len(processed_messages) > MESSAGE_CACHE_CLEANUP_THRESHOLD:
                cleanup_old_messages()

            # è®°å½•æ¶ˆæ¯ç±»å‹
            if message.outgoing:
                logger.debug(f"ğŸ“¤ outgoingæ¶ˆæ¯ï¼ˆç”±Botè½¬å‘ï¼‰: chat_id={message.chat.id}, message_id={message.id}")
            else:
                logger.debug(f"ğŸ“¥ incomingæ¶ˆæ¯ï¼ˆå¤–éƒ¨æ¥æºï¼‰: chat_id={message.chat.id}, message_id={message.id}")

            # è·å–æºchat ID
            source_chat_id = str(message.chat.id)

            # æ—©æœŸè¿‡æ»¤ï¼šæ£€æŸ¥æ­¤æºæ˜¯å¦è¢«ç›‘æ§ï¼ˆä½¿ç”¨ WatchServiceï¼‰
            watch_service = get_watch_service()
            monitored_sources = watch_service.get_monitored_sources()
            if source_chat_id not in monitored_sources:
                # è®°å½•è¢«è¿‡æ»¤çš„æ¶ˆæ¯ï¼ˆè°ƒè¯•ç”¨ï¼‰
                logger.debug(f"â­ï¸ æ¶ˆæ¯æ¥è‡ªéç›‘æ§æºï¼Œå·²è·³è¿‡: chat_id={source_chat_id}, message_id={message.id}")
                logger.debug(f"   å½“å‰ç›‘æ§æºåˆ—è¡¨: {monitored_sources if monitored_sources else 'ç©º'}")
                return

            logger.info(f"ğŸ”” ç›‘æ§æºæ¶ˆæ¯: chat_id={source_chat_id}, message_id={message.id}")

            # è·å–æ¶ˆæ¯æ–‡æœ¬
            message_text = message.text or message.caption or ""

            # æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…çš„ç›‘æ§é…ç½®ï¼ˆä½¿ç”¨ WatchServiceï¼‰
            from contextlib import nullcontext

            try:
                from src.infrastructure.monitoring.performance.decorators import performance_context
            except Exception:
                performance_context = None

            monitor_ctx = performance_context("bot.auto_forward.enqueue", tags={"component": "auto_forward"}) if performance_context else nullcontext()
            with monitor_ctx:
                tasks_for_source = watch_service.get_tasks_for_source(source_chat_id)
                enqueued_count = 0
                enqueued_forward_count = 0

                for entry in tasks_for_source:
                    if len(entry) == 3:
                        user_id, watch_key, task = entry
                    else:
                        user_id, task = entry
                        watch_key = source_chat_id

                    if hasattr(task, "to_dict"):
                        watch_data = task.to_dict()
                    elif isinstance(task, dict):
                        watch_data = task
                    else:
                        continue

                    dest = watch_data.get("dest")
                    record_mode = bool(watch_data.get("record_mode", False))
                    preserve_forward_source = bool(watch_data.get("preserve_forward_source", False))

                    logger.info(f"âœ… åŒ¹é…åˆ°ç›‘æ§ä»»åŠ¡: user={user_id}, source={source_chat_id}")

                    # è½¬å‘æ¨¡å¼ï¼šç”± worker åœ¨å¤„ç†é˜¶æ®µè´Ÿè´£ç¡®ä¿ Peer ç¼“å­˜å°±ç»ª
                    dest_chat_id = dest if not record_mode else None

                    # åª’ä½“ç»„å»é‡
                    if message.media_group_id:
                        mode_suffix = "record" if record_mode else "forward"
                        media_group_key = f"{user_id}_{watch_key}_{dest_chat_id}_{mode_suffix}_{message.media_group_id}"

                        if is_media_group_processed(media_group_key):
                            logger.debug(f"â­ï¸ è·³è¿‡å·²å¤„ç†çš„åª’ä½“ç»„: {media_group_key}")
                            continue

                        # æ³¨å†Œä¸ºå·²å¤„ç†
                        register_processed_media_group(media_group_key)
                        logger.info(f"ğŸ“¸ é¦–æ¬¡å¤„ç†åª’ä½“ç»„: {media_group_key}")

                    # åˆ›å»ºæ¶ˆæ¯å¯¹è±¡
                    msg_obj = Message(
                        user_id=user_id,
                        watch_key=watch_key,
                        source_chat_id=source_chat_id,
                        message_id=message.id,
                        watch_data=watch_data,
                        dest_chat_id=dest_chat_id,
                        message_text=message_text,
                        message=None,
                        media_group_key=f"{user_id}_{watch_key}_{message.media_group_id}" if message.media_group_id else None
                    )

                    # å…¥é˜Ÿæ¶ˆæ¯è¿›è¡Œå¤„ç†
                    try:
                        message_queue.put_nowait(msg_obj)
                    except queue.Full:
                        logger.warning(
                            f"ğŸš¨ é˜Ÿåˆ—å·²æ»¡ï¼Œä¸¢å¼ƒæ¶ˆæ¯: user={user_id}, source={source_chat_id}, message_id={message.id}"
                        )
                        if metrics is not None:
                            metrics.record_message_processed(
                                success=False,
                                category="auto_forward",
                                error_type="queue_full",
                            )
                        continue

                    enqueued_count += 1
                    logger.info(f"ğŸ“¬ æ¶ˆæ¯å·²å…¥é˜Ÿ: user={user_id}, source={source_chat_id}, é˜Ÿåˆ—å¤§å°={message_queue.qsize()}")
                    if not record_mode:
                        enqueued_forward_count += 1
                        if metrics is not None:
                            metrics.record_forward(success=True, preserve_source=preserve_forward_source)

                if enqueued_count > 0:
                    logger.info(f"âœ… æœ¬æ¬¡å…±å…¥é˜Ÿ {enqueued_count} æ¡æ¶ˆæ¯")
                    if metrics is not None:
                        metrics.record_message_processed(success=True, category="auto_forward", error_type=None)

        except (ValueError, KeyError) as e:
            error_msg = str(e)
            if "Peer id invalid" not in error_msg and "ID not found" not in error_msg:
                logger.error(f"âš ï¸ auto_forward é”™è¯¯: {type(e).__name__}: {e}", exc_info=True)
                try:
                    from src.infrastructure.monitoring.performance.business_metrics import get_business_metrics

                    get_business_metrics().record_message_processed(
                        success=False,
                        category="auto_forward",
                        error_type=type(e).__name__,
                    )
                except Exception as metrics_err:
                    logger.debug(f"ä¸šåŠ¡æŒ‡æ ‡ä¸ŠæŠ¥å¤±è´¥ï¼ˆå¿½ç•¥ï¼Œä¸å½±å“ä¸»æµç¨‹ï¼‰: {metrics_err}")
                try:
                    from src.infrastructure.monitoring.performance.business_metrics import get_business_metrics

                    get_business_metrics().record_forward(
                        success=False,
                        preserve_source=False,
                        error_type=type(e).__name__,
                    )
                except Exception as metrics_err:
                    logger.debug(f"ä¸šåŠ¡æŒ‡æ ‡ä¸ŠæŠ¥å¤±è´¥ï¼ˆå¿½ç•¥ï¼Œä¸å½±å“ä¸»æµç¨‹ï¼‰: {metrics_err}")
                try:
                    from src.infrastructure.monitoring.errors.tracker import get_error_tracker

                    get_error_tracker().track_error(
                        error=e,
                        context={"component": "auto_forward", "error_kind": type(e).__name__},
                    )
                except Exception as track_err:
                    logger.debug(f"é”™è¯¯è¿½è¸ªä¸ŠæŠ¥å¤±è´¥ï¼ˆå¿½ç•¥ï¼Œä¸å½±å“ä¸»æµç¨‹ï¼‰: {track_err}")
        except Exception as e:
            logger.error(f"âš ï¸ auto_forward æ„å¤–é”™è¯¯: {type(e).__name__}: {e}", exc_info=True)
            try:
                from src.infrastructure.monitoring.performance.business_metrics import get_business_metrics

                get_business_metrics().record_message_processed(
                    success=False,
                    category="auto_forward",
                    error_type=type(e).__name__,
                )
            except Exception as metrics_err:
                logger.debug(f"ä¸šåŠ¡æŒ‡æ ‡ä¸ŠæŠ¥å¤±è´¥ï¼ˆå¿½ç•¥ï¼Œä¸å½±å“ä¸»æµç¨‹ï¼‰: {metrics_err}")
            try:
                from src.infrastructure.monitoring.performance.business_metrics import get_business_metrics

                get_business_metrics().record_forward(
                    success=False,
                    preserve_source=False,
                    error_type=type(e).__name__,
                )
            except Exception as metrics_err:
                logger.debug(f"ä¸šåŠ¡æŒ‡æ ‡ä¸ŠæŠ¥å¤±è´¥ï¼ˆå¿½ç•¥ï¼Œä¸å½±å“ä¸»æµç¨‹ï¼‰: {metrics_err}")
            try:
                from src.infrastructure.monitoring.errors.tracker import get_error_tracker

                get_error_tracker().track_error(
                    error=e,
                    context={"component": "auto_forward", "error_kind": type(e).__name__},
                )
            except Exception as track_err:
                logger.debug(f"é”™è¯¯è¿½è¸ªä¸ŠæŠ¥å¤±è´¥ï¼ˆå¿½ç•¥ï¼Œä¸å½±å“ä¸»æµç¨‹ï¼‰: {track_err}")

    return auto_forward
