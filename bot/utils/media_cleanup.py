"""
åª’ä½“æ–‡ä»¶æ¸…ç†æ¨¡å—
å®šæœŸæ¸…ç†æ—§çš„æˆ–æœªä½¿ç”¨çš„åª’ä½“æ–‡ä»¶
"""
import os
import time
import logging
from datetime import datetime, timedelta
from typing import List, Tuple
import sqlite3
from config import MEDIA_DIR
from database import DATABASE_FILE

logger = logging.getLogger(__name__)


class MediaCleaner:
    """åª’ä½“æ–‡ä»¶æ¸…ç†å™¨"""
    
    def __init__(self, media_dir: str = MEDIA_DIR, db_file: str = DATABASE_FILE):
        """
        åˆå§‹åŒ–æ¸…ç†å™¨
        
        Args:
            media_dir: åª’ä½“æ–‡ä»¶ç›®å½•
            db_file: æ•°æ®åº“æ–‡ä»¶è·¯å¾„
        """
        self.media_dir = media_dir
        self.db_file = db_file
    
    def get_all_media_files(self) -> List[str]:
        """
        è·å–æ‰€æœ‰åª’ä½“æ–‡ä»¶åˆ—è¡¨
        
        Returns:
            List[str]: æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        media_files = []
        
        if not os.path.exists(self.media_dir):
            logger.warning(f"åª’ä½“ç›®å½•ä¸å­˜åœ¨: {self.media_dir}")
            return media_files
        
        for root, dirs, files in os.walk(self.media_dir):
            for file in files:
                file_path = os.path.join(root, file)
                media_files.append(file_path)
        
        return media_files
    
    def get_referenced_media_files(self) -> set:
        """
        è·å–æ•°æ®åº“ä¸­å¼•ç”¨çš„åª’ä½“æ–‡ä»¶
        
        Returns:
            set: è¢«å¼•ç”¨çš„æ–‡ä»¶è·¯å¾„é›†åˆ
        """
        referenced_files = set()
        
        try:
            conn = sqlite3.connect(self.db_file)
            try:
                from src.infrastructure.monitoring.performance.db_tracer import get_db_tracer

                conn = get_db_tracer().enable(conn)
            except Exception as e:
                logger.debug("db_tracer å¯ç”¨å¤±è´¥ï¼Œå·²å¿½ç•¥: %s", e, exc_info=True)
            cursor = conn.cursor()
            
            # æŸ¥è¯¢ media_path
            cursor.execute("SELECT media_path FROM notes WHERE media_path IS NOT NULL")
            for row in cursor.fetchall():
                if row[0]:
                    referenced_files.add(row[0])
            
            # æŸ¥è¯¢ media_paths (JSON æ•°ç»„)
            cursor.execute("SELECT media_paths FROM notes WHERE media_paths IS NOT NULL")
            for row in cursor.fetchall():
                if row[0]:
                    import json
                    try:
                        paths = json.loads(row[0])
                        referenced_files.update(paths)
                    except json.JSONDecodeError:
                        pass
            
            conn.close()
            
        except Exception as e:
            logger.error(f"æŸ¥è¯¢æ•°æ®åº“å¤±è´¥: {e}")
        
        return referenced_files
    
    def find_orphaned_files(self) -> List[str]:
        """
        æŸ¥æ‰¾å­¤ç«‹æ–‡ä»¶ï¼ˆæœªè¢«æ•°æ®åº“å¼•ç”¨ï¼‰
        
        Returns:
            List[str]: å­¤ç«‹æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        all_files = self.get_all_media_files()
        referenced_files = self.get_referenced_media_files()
        
        orphaned_files = []
        for file_path in all_files:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦è¢«å¼•ç”¨
            is_referenced = False
            for ref_path in referenced_files:
                if ref_path in file_path or file_path.endswith(os.path.basename(ref_path)):
                    is_referenced = True
                    break
            
            if not is_referenced:
                orphaned_files.append(file_path)
        
        return orphaned_files
    
    def find_old_files(self, days: int = 90) -> List[Tuple[str, float]]:
        """
        æŸ¥æ‰¾è¶…è¿‡æŒ‡å®šå¤©æ•°çš„æ—§æ–‡ä»¶
        
        Args:
            days: å¤©æ•°é˜ˆå€¼
            
        Returns:
            List[Tuple[str, float]]: (æ–‡ä»¶è·¯å¾„, æ–‡ä»¶å¤§å°) åˆ—è¡¨
        """
        threshold_time = time.time() - (days * 24 * 60 * 60)
        old_files = []
        
        all_files = self.get_all_media_files()
        for file_path in all_files:
            try:
                file_stat = os.stat(file_path)
                if file_stat.st_mtime < threshold_time:
                    old_files.append((file_path, file_stat.st_size))
            except OSError:
                pass
        
        return old_files
    
    def cleanup_orphaned_files(self, dry_run: bool = True) -> Tuple[int, int]:
        """
        æ¸…ç†å­¤ç«‹æ–‡ä»¶
        
        Args:
            dry_run: æ˜¯å¦ä¸ºæ¨¡æ‹Ÿè¿è¡Œï¼ˆä¸å®é™…åˆ é™¤ï¼‰
            
        Returns:
            Tuple[int, int]: (åˆ é™¤æ–‡ä»¶æ•°, é‡Šæ”¾ç©ºé—´å­—èŠ‚æ•°)
        """
        orphaned_files = self.find_orphaned_files()
        
        if not orphaned_files:
            logger.info("âœ… æ²¡æœ‰å‘ç°å­¤ç«‹æ–‡ä»¶")
            return 0, 0
        
        deleted_count = 0
        freed_space = 0
        
        logger.info(f"å‘ç° {len(orphaned_files)} ä¸ªå­¤ç«‹æ–‡ä»¶")
        
        for file_path in orphaned_files:
            try:
                file_size = os.path.getsize(file_path)
                
                if dry_run:
                    logger.info(f"[æ¨¡æ‹Ÿ] åˆ é™¤: {file_path} ({file_size} å­—èŠ‚)")
                else:
                    os.remove(file_path)
                    logger.info(f"åˆ é™¤: {file_path} ({file_size} å­—èŠ‚)")
                
                deleted_count += 1
                freed_space += file_size
                
            except Exception as e:
                logger.error(f"åˆ é™¤æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        return deleted_count, freed_space
    
    def cleanup_old_files(self, days: int = 90, dry_run: bool = True) -> Tuple[int, int]:
        """
        æ¸…ç†æ—§æ–‡ä»¶
        
        Args:
            days: å¤©æ•°é˜ˆå€¼
            dry_run: æ˜¯å¦ä¸ºæ¨¡æ‹Ÿè¿è¡Œ
            
        Returns:
            Tuple[int, int]: (åˆ é™¤æ–‡ä»¶æ•°, é‡Šæ”¾ç©ºé—´å­—èŠ‚æ•°)
        """
        old_files = self.find_old_files(days)
        
        if not old_files:
            logger.info(f"âœ… æ²¡æœ‰å‘ç°è¶…è¿‡ {days} å¤©çš„æ—§æ–‡ä»¶")
            return 0, 0
        
        deleted_count = 0
        freed_space = 0
        
        logger.info(f"å‘ç° {len(old_files)} ä¸ªè¶…è¿‡ {days} å¤©çš„æ—§æ–‡ä»¶")
        
        for file_path, file_size in old_files:
            try:
                if dry_run:
                    logger.info(f"[æ¨¡æ‹Ÿ] åˆ é™¤: {file_path} ({file_size} å­—èŠ‚)")
                else:
                    os.remove(file_path)
                    logger.info(f"åˆ é™¤: {file_path} ({file_size} å­—èŠ‚)")
                
                deleted_count += 1
                freed_space += file_size
                
            except Exception as e:
                logger.error(f"åˆ é™¤æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        return deleted_count, freed_space
    
    def get_storage_stats(self) -> dict:
        """
        è·å–å­˜å‚¨ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            dict: ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        all_files = self.get_all_media_files()
        total_size = sum(os.path.getsize(f) for f in all_files if os.path.exists(f))
        
        orphaned_files = self.find_orphaned_files()
        orphaned_size = sum(os.path.getsize(f) for f in orphaned_files if os.path.exists(f))
        
        return {
            'total_files': len(all_files),
            'total_size': total_size,
            'total_size_mb': total_size / (1024 * 1024),
            'orphaned_files': len(orphaned_files),
            'orphaned_size': orphaned_size,
            'orphaned_size_mb': orphaned_size / (1024 * 1024),
        }
    
    def print_stats(self):
        """æ‰“å°å­˜å‚¨ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.get_storage_stats()
        
        logger.info("=" * 60)
        logger.info("ğŸ“Š åª’ä½“å­˜å‚¨ç»Ÿè®¡")
        logger.info("=" * 60)
        logger.info(f"æ€»æ–‡ä»¶æ•°: {stats['total_files']}")
        logger.info(f"æ€»å¤§å°: {stats['total_size_mb']:.2f} MB")
        logger.info(f"å­¤ç«‹æ–‡ä»¶æ•°: {stats['orphaned_files']}")
        logger.info(f"å­¤ç«‹æ–‡ä»¶å¤§å°: {stats['orphaned_size_mb']:.2f} MB")
        logger.info("=" * 60)


# å‘½ä»¤è¡Œå·¥å…·
if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="åª’ä½“æ–‡ä»¶æ¸…ç†å·¥å…·")
    parser.add_argument("--stats", action="store_true", help="æ˜¾ç¤ºå­˜å‚¨ç»Ÿè®¡")
    parser.add_argument("--cleanup-orphaned", action="store_true", help="æ¸…ç†å­¤ç«‹æ–‡ä»¶")
    parser.add_argument("--cleanup-old", type=int, metavar="DAYS", help="æ¸…ç†è¶…è¿‡æŒ‡å®šå¤©æ•°çš„æ–‡ä»¶")
    parser.add_argument("--dry-run", action="store_true", help="æ¨¡æ‹Ÿè¿è¡Œï¼ˆä¸å®é™…åˆ é™¤ï¼‰")
    
    args = parser.parse_args()
    
    cleaner = MediaCleaner()
    
    if args.stats:
        cleaner.print_stats()
    
    if args.cleanup_orphaned:
        deleted, freed = cleaner.cleanup_orphaned_files(dry_run=args.dry_run)
        logger.info(f"{'[æ¨¡æ‹Ÿ] ' if args.dry_run else ''}åˆ é™¤ {deleted} ä¸ªæ–‡ä»¶ï¼Œé‡Šæ”¾ {freed / (1024*1024):.2f} MB")
    
    if args.cleanup_old:
        deleted, freed = cleaner.cleanup_old_files(days=args.cleanup_old, dry_run=args.dry_run)
        logger.info(f"{'[æ¨¡æ‹Ÿ] ' if args.dry_run else ''}åˆ é™¤ {deleted} ä¸ªæ–‡ä»¶ï¼Œé‡Šæ”¾ {freed / (1024*1024):.2f} MB")
