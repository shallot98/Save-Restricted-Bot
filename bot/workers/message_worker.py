"""
Message queue worker thread
Processes messages from the queue and handles forwarding/recording

Architecture: Uses new layered architecture
- src/core/container for service access
- src/application/services for business logic
"""
import time
import asyncio
import os
import heapq
import logging
import queue
import re
from dataclasses import dataclass, field
from typing import Optional, Dict, Any
from datetime import datetime
from zoneinfo import ZoneInfo
import pyrogram
from pyrogram.errors import FloodWait

# New architecture imports
from src.core.container import get_note_service, get_watch_service
from src.core.config import settings
from src.core.exceptions import ValidationError
from src.compat.config_compat import MEDIA_DIR
from src.domain.entities.watch import WatchTask
from src.domain.services.filter_service import FilterService
from src.domain.entities.note import NoteCreate

try:
    from src.infrastructure.monitoring.performance.decorators import monitor_performance
except Exception:
    def monitor_performance(*args, **kwargs):
        def _decorator(fn):
            return fn
        return _decorator

# Legacy imports
from bot.filters import extract_content
from bot.storage.webdav_client import WebDAVClient, StorageManager
from bot.utils.dedup import cleanup_old_messages
from bot.utils.magnet_utils import MagnetLinkParser
from constants import (
    MAX_RETRIES, MAX_FLOOD_RETRIES, OPERATION_TIMEOUT,
    WORKER_STATS_INTERVAL, RATE_LIMIT_DELAY, get_backoff_time, MAX_MEDIA_PER_GROUP
)

logger = logging.getLogger(__name__)

# China timezone
CHINA_TZ = ZoneInfo("Asia/Shanghai")


class UnrecoverableError(Exception):
    """Exception for unrecoverable errors that should not be retried"""
    pass


class RetryLater(Exception):
    """Exception indicating the message should be retried after a delay."""

    def __init__(self, delay_seconds: float, reason: str = "") -> None:
        super().__init__(reason or f"retry later: {delay_seconds}s")
        self.delay_seconds = delay_seconds
        self.reason = reason


@dataclass
class Message:
    """æ¶ˆæ¯å¯¹è±¡ï¼Œå°è£…æ¶ˆæ¯å…ƒæ•°æ®ï¼ˆä¼˜åŒ–ï¼šåªä¿ç•™å¿…è¦æ•°æ®ï¼Œå‡å°‘å†…å­˜å ç”¨ï¼‰"""
    user_id: str
    watch_key: str
    source_chat_id: str
    message_id: int
    watch_data: Dict[str, Any]
    dest_chat_id: Optional[str]
    message_text: str
    message: Optional[pyrogram.types.messages_and_media.message.Message] = None  # é‡è¯•æ—¶å¯æŒ‰éœ€é‡æ–°è·å–
    available_at: float = field(default_factory=time.time)
    timestamp: float = field(default_factory=time.time)
    retry_count: int = 0
    media_group_key: Optional[str] = None

    def __post_init__(self):
        """ä¼˜åŒ–ï¼šæ¸…ç†messageå¯¹è±¡ä¸­ä¸å¿…è¦çš„å¤§å‹å±æ€§ä»¥å‡å°‘å†…å­˜"""
        # æ³¨æ„ï¼šä¸èƒ½åˆ é™¤messageå¯¹è±¡æœ¬èº«ï¼Œå› ä¸ºè½¬å‘éœ€è¦å®ƒ
        # ä½†å¯ä»¥åœ¨å¤„ç†å®Œæˆåç”±workeræ¸…ç†
        pass


class MessageWorker:
    """æ¶ˆæ¯å·¥ä½œçº¿ç¨‹ï¼Œå¤„ç†é˜Ÿåˆ—ä¸­çš„æ¶ˆæ¯"""

    def __init__(self, message_queue: queue.Queue, acc_client, max_retries: int = MAX_RETRIES):
        self.message_queue = message_queue
        self.acc = acc_client
        self.max_retries = max_retries
        self.processed_count = 0
        self.failed_count = 0
        self.skipped_count = 0
        self.retry_count = 0
        self.running = True
        self.last_stats_time = time.time()
        self.loop = None
        self._delayed: list[tuple[float, int, Message]] = []
        self._delayed_seq: int = 0

        # åˆå§‹åŒ–å­˜å‚¨ç®¡ç†å™¨
        self.storage_manager = self._init_storage_manager()

    def _defer_message(self, msg_obj: Message) -> None:
        """å°†æ¶ˆæ¯æ”¾å…¥å†…éƒ¨å»¶è¿Ÿé˜Ÿåˆ—ï¼ˆæŒ‰ available_at è°ƒåº¦ï¼‰ã€‚"""
        self._delayed_seq += 1
        heapq.heappush(self._delayed, (msg_obj.available_at, self._delayed_seq, msg_obj))

    def _init_storage_manager(self) -> StorageManager:
        """åˆå§‹åŒ–å­˜å‚¨ç®¡ç†å™¨"""
        try:
            # åŠ è½½ WebDAV é…ç½®
            webdav_config = settings.webdav_config

            # å¦‚æœå¯ç”¨äº† WebDAV
            if webdav_config.get('enabled', False):
                url = webdav_config.get('url', '').strip()
                username = webdav_config.get('username', '').strip()
                password = webdav_config.get('password', '').strip()
                base_path = webdav_config.get('base_path', '/telegram_media')

                if url and username and password:
                    try:
                        webdav_client = WebDAVClient(url, username, password, base_path)

                        # æµ‹è¯•è¿æ¥
                        if webdav_client.test_connection():
                            logger.info("âœ… WebDAV å­˜å‚¨å·²å¯ç”¨")
                            return StorageManager(MEDIA_DIR, webdav_client)
                        else:
                            logger.warning("âš ï¸ WebDAV è¿æ¥æµ‹è¯•å¤±è´¥ï¼Œé™çº§åˆ°æœ¬åœ°å­˜å‚¨")
                    except Exception as e:
                        logger.error(f"âŒ WebDAV åˆå§‹åŒ–å¤±è´¥: {e}ï¼Œé™çº§åˆ°æœ¬åœ°å­˜å‚¨")
                else:
                    logger.warning("âš ï¸ WebDAV é…ç½®ä¸å®Œæ•´ï¼Œä½¿ç”¨æœ¬åœ°å­˜å‚¨")

            # ä½¿ç”¨æœ¬åœ°å­˜å‚¨
            logger.info("ğŸ“ ä½¿ç”¨æœ¬åœ°å­˜å‚¨æ¨¡å¼")
            return StorageManager(MEDIA_DIR)

        except Exception as e:
            logger.error(f"âŒ å­˜å‚¨ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}ï¼Œä½¿ç”¨æœ¬åœ°å­˜å‚¨")
            return StorageManager(MEDIA_DIR)

    def run(self):
        """ä¸»å¾ªç¯ï¼šæŒç»­å¤„ç†é˜Ÿåˆ—æ¶ˆæ¯"""
        import gc

        # Create event loop for this thread
        self.loop = asyncio.new_event_loop()
        asyncio.set_event_loop(self.loop)
        logger.info("ğŸ”§ æ¶ˆæ¯å·¥ä½œçº¿ç¨‹å·²å¯åŠ¨ï¼ˆå¸¦äº‹ä»¶å¾ªç¯ï¼‰")

        # ä¼˜åŒ–ï¼šè®°å½•åƒåœ¾å›æ”¶è®¡æ•°å™¨
        gc_counter = 0

        while self.running:
            msg_obj: Optional[Message] = None
            from_queue = False
            task_done_called = False

            try:
                now = time.time()

                # ä¼˜å…ˆå¤„ç†åˆ°æœŸçš„å»¶è¿Ÿæ¶ˆæ¯ï¼›å¦åˆ™é˜»å¡ç­‰å¾…é˜Ÿåˆ—æˆ–ä¸‹ä¸€ä¸ªå»¶è¿Ÿæ¶ˆæ¯åˆ°æœŸ
                if self._delayed and self._delayed[0][0] <= now:
                    _, _, msg_obj = heapq.heappop(self._delayed)
                else:
                    timeout = 1.0
                    if self._delayed:
                        timeout = min(timeout, max(0.0, self._delayed[0][0] - now))

                    try:
                        msg_obj = self.message_queue.get(timeout=timeout)
                        from_queue = True
                    except queue.Empty:
                        # Periodically log statistics and cleanup
                        if time.time() - self.last_stats_time > WORKER_STATS_INTERVAL:
                            queue_size = self.message_queue.qsize()
                            delayed_size = len(self._delayed)
                            if queue_size > 0 or delayed_size > 0 or self.processed_count > 0:
                                logger.info(
                                    "ğŸ“Š é˜Ÿåˆ—ç»Ÿè®¡: "
                                    f"å¾…å¤„ç†={queue_size}, å»¶è¿Ÿ={delayed_size}, "
                                    f"å·²å®Œæˆ={self.processed_count}, è·³è¿‡={self.skipped_count}, "
                                    f"å¤±è´¥={self.failed_count}, é‡è¯•={self.retry_count}"
                                )

                            # æ¸…ç†è¿‡æœŸçš„æ¶ˆæ¯ç¼“å­˜ï¼Œé˜²æ­¢å†…å­˜æ³„æ¼
                            cleanup_old_messages()

                            # ä¼˜åŒ–ï¼šå®šæœŸå¼ºåˆ¶åƒåœ¾å›æ”¶ï¼ˆæ¯3ä¸ªæ¸…ç†å‘¨æœŸï¼‰
                            gc_counter += 1
                            if gc_counter >= 3:
                                collected = gc.collect()
                                logger.debug(f"ğŸ§¹ å¼ºåˆ¶åƒåœ¾å›æ”¶: å›æ”¶äº† {collected} ä¸ªå¯¹è±¡")
                                gc_counter = 0

                            self.last_stats_time = time.time()
                        continue

                if msg_obj is None:
                    continue

                # è®°å½•é˜Ÿåˆ—ç»Ÿè®¡ä¿¡æ¯
                queue_size = self.message_queue.qsize()
                delayed_size = len(self._delayed)
                logger.info(
                    "ğŸ“¥ è·å–å¾…å¤„ç†æ¶ˆæ¯ "
                    f"(é˜Ÿåˆ—={queue_size}, å»¶è¿Ÿ={delayed_size}, "
                    f"å·²å¤„ç†={self.processed_count}, è·³è¿‡={self.skipped_count}, å¤±è´¥={self.failed_count})"
                )

                # æœªåˆ°æ‰§è¡Œæ—¶é—´ï¼šæ”¾å…¥å»¶è¿Ÿé˜Ÿåˆ—ï¼Œé¿å…åœ¨æœ‰ maxsize é˜Ÿåˆ—ä¸‹ requeue é˜»å¡
                now = time.time()
                if msg_obj.available_at > now:
                    self._defer_message(msg_obj)
                    if from_queue:
                        self.message_queue.task_done()
                        task_done_called = True
                    continue

                # å¤„ç†æ¶ˆæ¯
                result = self.process_message(msg_obj)

                if result == "success":
                    self.processed_count += 1
                    logger.info(f"âœ… æ¶ˆæ¯å¤„ç†æˆåŠŸ (æ€»è®¡: {self.processed_count})")
                    msg_obj.message = None
                elif result == "skip":
                    self.skipped_count += 1
                    logger.info(f"â­ï¸ æ¶ˆæ¯å·²è·³è¿‡ (æ€»è®¡: {self.skipped_count})")
                    msg_obj.message = None
                elif result == "retry":
                    # å¤±è´¥å¤„ç†ï¼šå»¶è¿Ÿé‡è¯•æˆ–æ”¾å¼ƒ
                    if msg_obj.retry_count < self.max_retries:
                        msg_obj.retry_count += 1
                        self.retry_count += 1
                        backoff_time = get_backoff_time(msg_obj.retry_count)
                        logger.warning(
                            f"âš ï¸ æ¶ˆæ¯å¤„ç†å¤±è´¥ï¼Œå°†åœ¨ {backoff_time} ç§’åé‡è¯• "
                            f"(ç¬¬ {msg_obj.retry_count}/{self.max_retries} æ¬¡)"
                        )
                        msg_obj.message = None
                        desired_available_at = time.time() + backoff_time
                        if msg_obj.available_at < desired_available_at:
                            msg_obj.available_at = desired_available_at
                        self._defer_message(msg_obj)
                        logger.info("ğŸ”„ æ¶ˆæ¯å·²åŠ å…¥å»¶è¿Ÿé˜Ÿåˆ—")
                    else:
                        self.failed_count += 1
                        logger.error(
                            f"âŒ æ¶ˆæ¯å¤„ç†æœ€ç»ˆå¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•° (æ€»å¤±è´¥: {self.failed_count})"
                        )
                        msg_obj.message = None

                try:
                    from src.infrastructure.monitoring.performance.business_metrics import get_business_metrics

                    get_business_metrics().record_message_processed(
                        success=result == "success",
                        category="worker_message",
                    )
                except Exception as metrics_err:
                    logger.debug(f"ä¸šåŠ¡æŒ‡æ ‡ä¸ŠæŠ¥å¤±è´¥ï¼ˆå¿½ç•¥ï¼Œä¸å½±å“ä¸»æµç¨‹ï¼‰: {metrics_err}")

            except Exception as e:
                logger.error(f"âš ï¸ å·¥ä½œçº¿ç¨‹å¼‚å¸¸: {e}", exc_info=True)
                try:
                    from src.infrastructure.monitoring.errors.tracker import get_error_tracker

                    get_error_tracker().track_error(
                        error=e,
                        context={"component": "message_worker", "stage": "outer_loop"},
                    )
                except Exception as track_err:
                    logger.debug(f"é”™è¯¯è¿½è¸ªä¸ŠæŠ¥å¤±è´¥ï¼ˆå¿½ç•¥ï¼Œä¸å½±å“ä¸»æµç¨‹ï¼‰: {track_err}")
            finally:
                if from_queue and not task_done_called:
                    try:
                        self.message_queue.task_done()
                    except ValueError:
                        pass
        
        # Clean up event loop
        if self.loop:
            self.loop.close()
        logger.info("ğŸ›‘ æ¶ˆæ¯å·¥ä½œçº¿ç¨‹å·²åœæ­¢")
    
    def _run_async_with_timeout(self, coro, timeout: float = OPERATION_TIMEOUT):
        """Execute async operation with timeout in the worker thread"""
        # Validate that we have a proper coroutine or awaitable
        if not asyncio.iscoroutine(coro) and not hasattr(coro, '__await__'):
            error_msg = f"Expected coroutine or awaitable, got {type(coro).__name__}"
            logger.error(f"âŒ {error_msg}")
            raise TypeError(error_msg)
        
        # Ensure event loop exists and is valid
        if not self.loop or self.loop.is_closed():
            error_msg = "Event loop not available or closed"
            logger.error(f"âŒ {error_msg}")
            raise RuntimeError(error_msg)
        
        try:
            return self.loop.run_until_complete(
                asyncio.wait_for(coro, timeout=timeout)
            )
        except asyncio.TimeoutError:
            logger.error(f"âŒ æ“ä½œè¶…æ—¶ï¼ˆ{timeout}ç§’ï¼‰")
            raise

    @staticmethod
    def _coerce_chat_id(chat_id: str):
        """å°† chat_id è§„èŒƒä¸º Pyrogram å¯æ¥å—çš„ç±»å‹ï¼ˆint æˆ–å­—ç¬¦ä¸²ï¼‰ã€‚"""
        if chat_id == "me":
            return "me"
        try:
            return int(chat_id)
        except Exception:
            return chat_id

    def _ensure_message_loaded(self, msg_obj: Message):
        """ç¡®ä¿ msg_obj.message å¯ç”¨äºå¤„ç†ï¼ˆé‡è¯•æ—¶æŒ‰éœ€é‡æ–°è·å–ï¼‰ã€‚"""
        if msg_obj.message is not None:
            if not msg_obj.message_text:
                msg_obj.message_text = msg_obj.message.text or msg_obj.message.caption or ""
                if (
                    self.acc
                    and not msg_obj.message_text
                    and getattr(msg_obj.message, "media_group_id", None)
                ):
                    chat_id = self._coerce_chat_id(msg_obj.source_chat_id)
                    try:
                        media_group = self._execute_with_flood_retry(
                            "è·å–åª’ä½“ç»„æ–‡æœ¬",
                            lambda: self.acc.get_media_group(chat_id, msg_obj.message_id),
                        )
                        if media_group:
                            first = media_group[0]
                            msg_obj.message_text = first.text or first.caption or ""
                    except RetryLater:
                        raise
                    except Exception as e:
                        logger.debug(f"ğŸ“¸ è·å–åª’ä½“ç»„æ–‡æœ¬å¤±è´¥: {e}")
            return msg_obj.message

        if not self.acc:
            raise UnrecoverableError("User client æœªåˆå§‹åŒ–ï¼Œæ— æ³•é‡æ–°è·å–æ¶ˆæ¯")

        chat_id = self._coerce_chat_id(msg_obj.source_chat_id)
        try:
            from bot.services.peer_cache import cache_peer_if_needed

            if chat_id != "me":
                cache_peer_if_needed(self.acc, chat_id, "æºé¢‘é“")
        except Exception as e:
            logger.debug(f"æºé¢‘é“ Peer ç¼“å­˜é¢„çƒ­å¤±è´¥ï¼ˆå¿½ç•¥ï¼Œä¸å½±å“ä¸»æµç¨‹ï¼‰: {e}")
        fetched = self._execute_with_flood_retry(
            "é‡æ–°è·å–æ¶ˆæ¯",
            lambda: self.acc.get_messages(chat_id, msg_obj.message_id),
        )

        if isinstance(fetched, list):
            fetched = fetched[0] if fetched else None

        if not fetched:
            raise UnrecoverableError(f"æ— æ³•é‡æ–°è·å–æ¶ˆæ¯: {msg_obj.source_chat_id}/{msg_obj.message_id}")

        msg_obj.message = fetched

        if not msg_obj.message_text:
            msg_obj.message_text = fetched.text or fetched.caption or ""
            if not msg_obj.message_text and getattr(fetched, "media_group_id", None):
                media_group = self._execute_with_flood_retry(
                    "è·å–åª’ä½“ç»„æ–‡æœ¬",
                    lambda: self.acc.get_media_group(chat_id, msg_obj.message_id),
                )
                if media_group:
                    first = media_group[0]
                    msg_obj.message_text = first.text or first.caption or ""

        return fetched
    
    def _execute_with_flood_retry(self, operation_name: str, operation_func, max_flood_retries: int = MAX_FLOOD_RETRIES, timeout: float = OPERATION_TIMEOUT):
        """Execute operation with FloodWait retry and timeout handling

        Returns:
            æ“ä½œçš„è¿”å›ç»“æœï¼ˆæ¶ˆæ¯å¯¹è±¡æˆ–æ¶ˆæ¯IDåˆ—è¡¨ï¼‰
        """
        for flood_attempt in range(max_flood_retries):
            try:
                result = operation_func()
                # Check if result is a coroutine (async operation)
                if asyncio.iscoroutine(result):
                    result = self._run_async_with_timeout(result, timeout=timeout)
                return result
            except FloodWait as e:
                wait_time = e.value
                if flood_attempt < max_flood_retries - 1:
                    logger.warning(f"â³ {operation_name}: é‡åˆ°é™æµ FLOOD_WAIT, éœ€ç­‰å¾… {wait_time} ç§’")
                    logger.info(f"   å°†åœ¨ {wait_time + 1} ç§’åé‡è¯• (FloodWait é‡è¯• {flood_attempt + 1}/{max_flood_retries})")
                    raise RetryLater(wait_time + 1, reason=f"{operation_name}: FLOOD_WAIT")
                else:
                    logger.error(f"âŒ {operation_name}: FloodWait é‡è¯•æ¬¡æ•°å·²è¾¾ä¸Šé™ï¼Œæ”¾å¼ƒæ“ä½œ")
                    raise UnrecoverableError(f"FloodWait retry limit exceeded for {operation_name}")
            except asyncio.TimeoutError:
                logger.error(f"âŒ {operation_name}: æ“ä½œè¶…æ—¶ï¼ˆ{timeout}ç§’ï¼‰ï¼Œè·³è¿‡æ­¤æ¶ˆæ¯")
                raise UnrecoverableError(f"Timeout ({timeout}s) for {operation_name}")
            except TypeError as e:
                error_msg = str(e)
                if "coroutine" in error_msg.lower() or "awaitable" in error_msg.lower():
                    logger.error(f"âŒ {operation_name}: å¼‚æ­¥æ‰§è¡Œé”™è¯¯: {error_msg}")
                    raise UnrecoverableError(f"Async execution error for {operation_name}: {error_msg}")
                else:
                    logger.error(f"âŒ {operation_name} æ‰§è¡Œå¤±è´¥: {type(e).__name__}: {e}")
                    raise
            except (ValueError, KeyError) as e:
                error_msg = str(e)
                if "Peer id invalid" in error_msg or "ID not found" in error_msg:
                    logger.warning(f"âš ï¸ {operation_name}: Peer ID æ— æ•ˆï¼Œè·³è¿‡: {error_msg}")
                    raise UnrecoverableError(f"Invalid Peer ID: {error_msg}")
                else:
                    logger.error(f"âŒ {operation_name} æ‰§è¡Œå¤±è´¥: {type(e).__name__}: {e}")
                    raise
            except Exception as e:
                logger.error(f"âŒ {operation_name} æ‰§è¡Œå¤±è´¥: {type(e).__name__}: {e}")
                raise
        raise UnrecoverableError(f"Operation {operation_name} failed after {max_flood_retries} FloodWait retries")
    
    @monitor_performance("worker.process_message")
    def process_message(self, msg_obj: Message) -> str:
        """å¤„ç†å•æ¡æ¶ˆæ¯
        
        Returns:
            "success": Message processed successfully
            "skip": Message skipped (filters or unrecoverable errors)
            "retry": Message failed but can be retried
        """
        try:
            logger.info(f"âš™ï¸ å¼€å§‹å¤„ç†æ¶ˆæ¯: user={msg_obj.user_id}, source={msg_obj.source_chat_id}")
            logger.debug(f"   é‡è¯•æ¬¡æ•°: {msg_obj.retry_count}, æ¶ˆæ¯æ–‡æœ¬: {msg_obj.message_text[:100] if msg_obj.message_text else 'None'}...")
            
            message = self._ensure_message_loaded(msg_obj)
            watch_data = msg_obj.watch_data
            user_id = msg_obj.user_id
            source_chat_id = msg_obj.source_chat_id
            dest_chat_id = msg_obj.dest_chat_id
            message_text = msg_obj.message_text
            
            # æå–é…ç½®
            whitelist = watch_data.get("whitelist", [])
            blacklist = watch_data.get("blacklist", [])
            whitelist_regex = watch_data.get("whitelist_regex", [])
            blacklist_regex = watch_data.get("blacklist_regex", [])
            preserve_forward_source = watch_data.get("preserve_forward_source", False)
            forward_mode = watch_data.get("forward_mode", "full")
            extract_patterns = watch_data.get("extract_patterns", [])
            record_mode = watch_data.get("record_mode", False)
            # å·²åˆ é™¤ append_dn é…ç½®ï¼ˆä¸å†ä½¿ç”¨DNè¡¥å…¨åŠŸèƒ½ï¼‰
            
            # å†æ¬¡éªŒè¯è¿‡æ»¤è§„åˆ™ï¼ˆé˜²æ­¢é…ç½®åœ¨å…¥é˜Ÿåè¢«ä¿®æ”¹ï¼‰
            task = WatchTask(
                source=str(source_chat_id),
                dest=dest_chat_id,
                whitelist=whitelist,
                blacklist=blacklist,
                whitelist_regex=whitelist_regex,
                blacklist_regex=blacklist_regex,
                preserve_forward_source=preserve_forward_source,
                forward_mode=forward_mode,
                extract_patterns=extract_patterns,
                record_mode=record_mode,
            )

            if not FilterService.should_forward(task, message_text):
                logger.info("â­ï¸ æ¶ˆæ¯æœªé€šè¿‡è¿‡æ»¤è§„åˆ™ï¼Œå·²è·³è¿‡")
                return "skip"
            
            logger.info(f"ğŸ¯ æ¶ˆæ¯é€šè¿‡æ‰€æœ‰è¿‡æ»¤è§„åˆ™ï¼Œå‡†å¤‡å¤„ç†")
            
            # Record mode - save to database
            if record_mode:
                return self._handle_record_mode(message, user_id, source_chat_id, message_text, forward_mode, extract_patterns)
            
            # Forward mode
            else:
                return self._handle_forward_mode(message, dest_chat_id, message_text, forward_mode, extract_patterns, preserve_forward_source, record_mode)
            
        except RetryLater as e:
            msg_obj.available_at = max(msg_obj.available_at, time.time() + e.delay_seconds)
            logger.warning(f"â³ æ¶ˆæ¯éœ€å»¶è¿Ÿé‡è¯•ï¼ˆ{e.delay_seconds}ç§’ï¼‰: {e.reason or str(e)}")
            return "retry"
        except UnrecoverableError as e:
            logger.warning(f"âš ï¸ æ¶ˆæ¯å¤„ç†å¤±è´¥ï¼ˆä¸å¯æ¢å¤ï¼‰ï¼Œè·³è¿‡: {e}")
            return "skip"
        except (ValueError, KeyError) as e:
            error_msg = str(e)
            if "Peer id invalid" in error_msg or "ID not found" in error_msg:
                logger.warning(f"âš ï¸ è·³è¿‡æ— æ•ˆçš„ Peer ID é”™è¯¯: {error_msg}")
                return "skip"
            else:
                logger.error(f"âŒ å¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™: {type(e).__name__}: {e}", exc_info=True)
                try:
                    from src.infrastructure.monitoring.errors.tracker import get_error_tracker

                    get_error_tracker().track_error(
                        error=e,
                        context={
                            "component": "message_worker",
                            "stage": "process_message",
                            "user_id": msg_obj.user_id,
                            "source_chat_id": msg_obj.source_chat_id,
                            "watch_key": msg_obj.watch_key,
                        },
                    )
                except Exception as track_err:
                    logger.debug(f"é”™è¯¯è¿½è¸ªä¸ŠæŠ¥å¤±è´¥ï¼ˆå¿½ç•¥ï¼Œä¸å½±å“ä¸»æµç¨‹ï¼‰: {track_err}")
                return "retry"
        except Exception as e:
            logger.error(f"âŒ å¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™: {e}", exc_info=True)
            try:
                from src.infrastructure.monitoring.errors.tracker import get_error_tracker

                get_error_tracker().track_error(
                    error=e,
                    context={
                        "component": "message_worker",
                        "stage": "process_message",
                        "user_id": msg_obj.user_id,
                        "source_chat_id": msg_obj.source_chat_id,
                        "watch_key": msg_obj.watch_key,
                    },
                )
            except Exception as track_err:
                logger.debug(f"é”™è¯¯è¿½è¸ªä¸ŠæŠ¥å¤±è´¥ï¼ˆå¿½ç•¥ï¼Œä¸å½±å“ä¸»æµç¨‹ï¼‰: {track_err}")
            return "retry"
    
    @monitor_performance("worker.handle_record_mode")
    def _handle_record_mode(self, message, user_id, source_chat_id, message_text, forward_mode, extract_patterns):
        """Handle record mode processing"""
        logger.info(f"ğŸ“ è®°å½•æ¨¡å¼ï¼šå¼€å§‹å¤„ç†æ¶ˆæ¯")
        logger.info(f"   æ¥æº: {source_chat_id} ({getattr(message.chat, 'title', None) or getattr(message.chat, 'username', None)})")
        source_name = message.chat.title or message.chat.username or source_chat_id
        
        # Handle text content with extraction
        content_to_save = message_text
        logger.debug(f"   åŸå§‹å†…å®¹é•¿åº¦: {len(message_text)}")
        
        if forward_mode == "extract" and extract_patterns:
            content_to_save = extract_content(message_text, extract_patterns)
        
        # Handle media
        media_type = None
        media_path = None
        media_paths = []
        
        logger.debug(f"   å¼€å§‹å¤„ç†åª’ä½“")
        
        # Check if this is a media group (multiple images)
        if message.media_group_id:
            media_type, media_path, media_paths, content_to_save = self._handle_media_group(message, content_to_save)
        
        # Single photo
        elif message.photo:
            media_type, media_path, media_paths = self._handle_single_photo(message)
        
        # Single video
        elif message.video:
            media_type, media_path, media_paths = self._handle_single_video(message)
        
        # Single animation (GIF)
        elif message.animation:
            media_type, media_path, media_paths = self._handle_single_animation(message)
        
        # Save to database
        logger.info(f"ğŸ’¾ è®°å½•æ¨¡å¼ï¼šå‡†å¤‡ä¿å­˜ç¬”è®°åˆ°æ•°æ®åº“")
        logger.info(f"   - ç”¨æˆ·ID: {user_id}")
        logger.info(f"   - æ¥æº: {source_name} ({source_chat_id})")
        logger.info(f"   - æ–‡æœ¬: {bool(content_to_save)} ({len(content_to_save) if content_to_save else 0} å­—ç¬¦)")
        logger.info(f"   - åª’ä½“ç±»å‹: {media_type}")
        logger.info(f"   - åª’ä½“æ•°é‡: {len(media_paths)} ä¸ª")
        logger.info(f"   - åª’ä½“ç»„ID: {message.media_group_id if message.media_group_id else 'None'}")
        
        try:
            note_service = get_note_service()

            note_dto = note_service.create_note(
                NoteCreate(
                    user_id=int(user_id),
                    source_chat_id=source_chat_id,
                    source_name=source_name,
                    message_text=content_to_save if content_to_save else None,
                    media_type=media_type,
                    media_path=media_path,
                    media_paths=media_paths if media_paths else None,
                    media_group_id=str(message.media_group_id) if message.media_group_id else None,
                )
            )

            note_id = note_dto.id

            magnet_link = (
                MagnetLinkParser.extract_magnet_from_text(content_to_save)
                if content_to_save
                else None
            )
            if magnet_link:
                note_service.update_magnet(note_id, magnet_link, filename=None)

            logger.info(f"âœ… è®°å½•æ¨¡å¼ï¼šç¬”è®°ä¿å­˜æˆåŠŸï¼ç¬”è®°ID: {note_id}")
            try:
                from src.infrastructure.monitoring.performance.business_metrics import get_business_metrics

                get_business_metrics().record_note_saved(
                    success=True,
                    has_media=bool(media_type),
                )
            except Exception as metrics_err:
                logger.debug(f"ä¸šåŠ¡æŒ‡æ ‡ä¸ŠæŠ¥å¤±è´¥ï¼ˆå¿½ç•¥ï¼Œä¸å½±å“ä¸»æµç¨‹ï¼‰: {metrics_err}")
            return "success"
        except ValidationError as e:
            if "Duplicate" in str(e):
                logger.info("â­ï¸ è®°å½•æ¨¡å¼ï¼šæ£€æµ‹åˆ°é‡å¤ç¬”è®°ï¼Œå·²è·³è¿‡å†™å…¥")
                return "success"
            raise
        except Exception as e:
            logger.error(f"âŒ è®°å½•æ¨¡å¼ï¼šä¿å­˜ç¬”è®°å¤±è´¥ï¼", exc_info=True)
            try:
                from src.infrastructure.monitoring.performance.business_metrics import get_business_metrics

                get_business_metrics().record_note_saved(
                    success=False,
                    has_media=bool(media_type),
                    error_type=type(e).__name__,
                )
            except Exception as metrics_err:
                logger.debug(f"ä¸šåŠ¡æŒ‡æ ‡ä¸ŠæŠ¥å¤±è´¥ï¼ˆå¿½ç•¥ï¼Œä¸å½±å“ä¸»æµç¨‹ï¼‰: {metrics_err}")
            raise
    
    def _download_and_save_media(self, file_id: str, file_name: str, keep_local: bool) -> tuple[bool, Optional[str]]:
        """ä¸‹è½½å¹¶ä¿å­˜å•ä¸ªåª’ä½“æ–‡ä»¶

        Args:
            file_id: Telegram æ–‡ä»¶ ID
            file_name: ä¿å­˜çš„æ–‡ä»¶å
            keep_local: æ˜¯å¦ä¿ç•™æœ¬åœ°å‰¯æœ¬

        Returns:
            (success, storage_location): æ˜¯å¦æˆåŠŸå’Œå­˜å‚¨ä½ç½®
        """
        file_path = os.path.join(MEDIA_DIR, file_name)
        try:
            self.acc.download_media(file_id, file_name=file_path)
            return self.storage_manager.save_file(file_path, file_name, keep_local=keep_local)
        except Exception as e:
            logger.error(f"      âŒ ä¸‹è½½åª’ä½“å¤±è´¥: {e}")
            return False, None

    def _process_single_media_in_group(self, msg, idx: int, keep_local: bool,
                                       media_type: Optional[str]) -> tuple[Optional[str], bool, Optional[str]]:
        """å¤„ç†åª’ä½“ç»„ä¸­çš„å•ä¸ªåª’ä½“

        Args:
            msg: åª’ä½“æ¶ˆæ¯å¯¹è±¡
            idx: åª’ä½“ç´¢å¼•
            keep_local: æ˜¯å¦ä¿ç•™æœ¬åœ°å‰¯æœ¬
            media_type: å½“å‰åª’ä½“ç±»å‹

        Returns:
            (media_type, saved, storage_location): åª’ä½“ç±»å‹ã€æ˜¯å¦ä¿å­˜æˆåŠŸã€å­˜å‚¨ä½ç½®
        """
        timestamp = datetime.now(CHINA_TZ).strftime('%Y%m%d_%H%M%S')

        # å¤„ç†å›¾ç‰‡
        if msg.photo:
            file_name = f"{msg.id}_{idx}_{timestamp}.jpg"
            success, location = self._download_and_save_media(msg.photo.file_id, file_name, keep_local)
            if success:
                logger.debug(f"      âœ… ä¿å­˜å›¾ç‰‡: {file_name}")
            return "photo", success, location

        # å¤„ç†è§†é¢‘ç¼©ç•¥å›¾
        if msg.video:
            new_type = media_type or "video"
            if msg.video.thumbs and len(msg.video.thumbs) > 0:
                thumb = msg.video.thumbs[-1]
                file_name = f"{msg.id}_{idx}_thumb_{timestamp}.jpg"
                success, location = self._download_and_save_media(thumb.file_id, file_name, keep_local)
                if success:
                    logger.debug(f"      âœ… ä¿å­˜è§†é¢‘ç¼©ç•¥å›¾: {file_name}")
                return new_type, success, location
            return new_type, False, None

        # å¤„ç† GIF åŠ¨å›¾ç¼©ç•¥å›¾
        if msg.animation:
            new_type = media_type or "animation"
            if msg.animation.thumbs and len(msg.animation.thumbs) > 0:
                thumb = msg.animation.thumbs[-1]
                file_name = f"{msg.id}_{idx}_gif_thumb_{timestamp}.jpg"
                success, location = self._download_and_save_media(thumb.file_id, file_name, keep_local)
                if success:
                    logger.debug(f"      âœ… ä¿å­˜GIFç¼©ç•¥å›¾: {file_name}")
                return new_type, success, location
            return new_type, False, None

        return media_type, False, None

    def _handle_media_group(self, message, content_to_save):
        """Handle media group download"""
        media_type = None
        media_path = None
        media_paths = []

        webdav_config = settings.webdav_config
        keep_local = webdav_config.get('keep_local_copy', False)

        try:
            media_group = self.acc.get_media_group(message.chat.id, message.id)
            if not media_group:
                raise Exception("æ— æ³•è·å–åª’ä½“ç»„")

            logger.info(f"   ğŸ“· å‘ç°åª’ä½“ç»„ï¼Œå…± {len(media_group)} ä¸ªåª’ä½“")

            for idx, msg in enumerate(media_group):
                # å¤„ç†å•ä¸ªåª’ä½“
                media_type, saved, storage_location = self._process_single_media_in_group(
                    msg, idx, keep_local, media_type
                )

                if saved and storage_location:
                    media_paths.append(storage_location)
                    if idx == 0:
                        media_path = storage_location
                else:
                    logger.warning(f"      âš ï¸ åª’ä½“ {idx+1} ç±»å‹ä¸æ”¯æŒæˆ–æ— ç¼©ç•¥å›¾")

                # æ£€æŸ¥åª’ä½“æ•°é‡é™åˆ¶
                if len(media_paths) >= MAX_MEDIA_PER_GROUP:
                    logger.warning(f"   âš ï¸ åª’ä½“ç»„è¶…è¿‡{MAX_MEDIA_PER_GROUP}ä¸ªï¼Œä»…ä¿å­˜å‰{MAX_MEDIA_PER_GROUP}ä¸ª")
                    break

                # æå– caption
                if msg.caption and not content_to_save:
                    content_to_save = msg.caption

            logger.info(f"   âœ… åª’ä½“ç»„å¤„ç†å®Œæˆï¼Œå…±ä¿å­˜ {len(media_paths)} ä¸ªæ–‡ä»¶")

        except Exception as e:
            logger.error(f"   âŒ è·å–åª’ä½“ç»„å¤±è´¥: {e}", exc_info=True)
            if message.photo:
                media_type, media_path, media_paths = self._handle_single_photo(message)

        return media_type, media_path, media_paths, content_to_save
    
    def _handle_single_photo(self, message):
        """Handle single photo download"""
        logger.info(f"   ğŸ“· å¤„ç†å•å¼ å›¾ç‰‡")
        media_type = "photo"
        file_name = f"{message.id}_{datetime.now(CHINA_TZ).strftime('%Y%m%d_%H%M%S')}.jpg"
        file_path = os.path.join(MEDIA_DIR, file_name)

        # ä¸‹è½½åˆ°æœ¬åœ°ä¸´æ—¶æ–‡ä»¶
        self.acc.download_media(message.photo.file_id, file_name=file_path)

        # ä½¿ç”¨å­˜å‚¨ç®¡ç†å™¨ä¿å­˜
        webdav_config = settings.webdav_config
        keep_local = webdav_config.get('keep_local_copy', False)
        success, storage_location = self.storage_manager.save_file(file_path, file_name, keep_local=keep_local)

        if success:
            return media_type, storage_location, [storage_location]
        else:
            logger.warning(f"âš ï¸ å­˜å‚¨å¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°è·¯å¾„: {file_name}")
            return media_type, file_name, [file_name]
    
    def _handle_single_video(self, message):
        """Handle single video thumbnail download"""
        logger.info(f"   ğŸ“¹ å¤„ç†è§†é¢‘æ¶ˆæ¯")
        media_type = "video"
        media_path = None
        media_paths = []

        try:
            if message.video.thumbs and len(message.video.thumbs) > 0:
                thumb = message.video.thumbs[-1]
                file_name = f"{message.id}_{datetime.now(CHINA_TZ).strftime('%Y%m%d_%H%M%S')}_thumb.jpg"
                file_path = os.path.join(MEDIA_DIR, file_name)

                # ä¸‹è½½åˆ°æœ¬åœ°ä¸´æ—¶æ–‡ä»¶
                self.acc.download_media(thumb.file_id, file_name=file_path)

                # ä½¿ç”¨å­˜å‚¨ç®¡ç†å™¨ä¿å­˜
                webdav_config = settings.webdav_config
                keep_local = webdav_config.get('keep_local_copy', False)
                success, storage_location = self.storage_manager.save_file(file_path, file_name, keep_local=keep_local)

                if success:
                    media_path = storage_location
                    media_paths = [storage_location]
                else:
                    media_path = f"local:{file_name}"
                    media_paths = [media_path]

                logger.info(f"   âœ… è§†é¢‘ç¼©ç•¥å›¾å·²ä¿å­˜")
            else:
                logger.warning(f"   âš ï¸ è§†é¢‘æ²¡æœ‰ç¼©ç•¥å›¾")
        except Exception as e:
            logger.warning(f"   âš ï¸ ä¸‹è½½è§†é¢‘ç¼©ç•¥å›¾å¤±è´¥: {e}")

        return media_type, media_path, media_paths
    
    def _handle_single_animation(self, message):
        """Handle single GIF animation thumbnail download"""
        logger.info(f"   ğŸï¸ å¤„ç†GIFåŠ¨å›¾æ¶ˆæ¯")
        media_type = "animation"
        media_path = None
        media_paths = []

        try:
            if message.animation.thumbs and len(message.animation.thumbs) > 0:
                thumb = message.animation.thumbs[-1]
                file_name = f"{message.id}_{datetime.now(CHINA_TZ).strftime('%Y%m%d_%H%M%S')}_gif_thumb.jpg"
                file_path = os.path.join(MEDIA_DIR, file_name)

                # ä¸‹è½½åˆ°æœ¬åœ°ä¸´æ—¶æ–‡ä»¶
                self.acc.download_media(thumb.file_id, file_name=file_path)

                # ä½¿ç”¨å­˜å‚¨ç®¡ç†å™¨ä¿å­˜
                webdav_config = settings.webdav_config
                keep_local = webdav_config.get('keep_local_copy', False)
                success, storage_location = self.storage_manager.save_file(file_path, file_name, keep_local=keep_local)

                if success:
                    media_path = storage_location
                    media_paths = [storage_location]
                else:
                    media_path = f"local:{file_name}"
                    media_paths = [media_path]

                logger.info(f"   âœ… GIFç¼©ç•¥å›¾å·²ä¿å­˜")
            else:
                logger.warning(f"   âš ï¸ GIFåŠ¨å›¾æ²¡æœ‰ç¼©ç•¥å›¾")
        except Exception as e:
            logger.warning(f"   âš ï¸ ä¸‹è½½GIFç¼©ç•¥å›¾å¤±è´¥: {e}")

        return media_type, media_path, media_paths
    
    @monitor_performance("worker.handle_forward_mode")
    def _handle_forward_mode(self, message, dest_chat_id, message_text, forward_mode, extract_patterns, preserve_forward_source, record_mode):
        """Handle forward mode processing"""
        logger.info(f"ğŸ“¤ è½¬å‘æ¨¡å¼ï¼šå¼€å§‹å¤„ç†ï¼Œç›®æ ‡: {dest_chat_id}")

        if not dest_chat_id:
            raise UnrecoverableError("ç›®æ ‡é¢‘é“ä¸ºç©ºï¼Œæ— æ³•è½¬å‘")

        # ç›®æ ‡ Peer ç¼“å­˜ç”± worker è´Ÿè´£ï¼Œé¿å…åœ¨å›è°ƒçº¿ç¨‹è¿›è¡Œé‡æ“ä½œ
        if dest_chat_id != "me":
            if not self._ensure_peer_cached(str(dest_chat_id)):
                raise UnrecoverableError(f"ç›®æ ‡ Peer ç¼“å­˜å¤±è´¥: {dest_chat_id}")

        # ç”¨äºå­˜å‚¨è½¬å‘åçš„æ–°æ¶ˆæ¯ID(ç”¨äºé“¾å¼è½¬å‘)
        forwarded_message_id = None

        try:
            # Extract mode
            if forward_mode == "extract" and extract_patterns:
                extracted_text = extract_content(message_text, extract_patterns)

                if extracted_text:
                    logger.info(f"   æå–åˆ°å†…å®¹ï¼Œå‡†å¤‡å‘é€")
                    dest_id = "me" if dest_chat_id == "me" else int(dest_chat_id)
                    sent_msg = self._execute_with_flood_retry(
                        "å‘é€æå–å†…å®¹",
                        lambda: self.acc.send_message(dest_id, extracted_text)
                    )
                    if sent_msg:
                        forwarded_message_id = sent_msg.id if hasattr(sent_msg, 'id') else None
                    logger.info(f"   âœ… æå–å†…å®¹å·²å‘é€")
                    time.sleep(RATE_LIMIT_DELAY)
                else:
                    logger.debug(f"   æœªæå–åˆ°ä»»ä½•å†…å®¹ï¼Œè·³è¿‡å‘é€")

            # Full forward mode
            else:
                dest_id = "me" if dest_chat_id == "me" else int(dest_chat_id)

                # æ­£å¸¸è½¬å‘ï¼ˆå·²åˆ é™¤DNè¡¥å…¨åŠŸèƒ½ï¼‰
                if preserve_forward_source:
                    forwarded_message_id = self._forward_with_source(message, dest_id)
                else:
                    forwarded_message_id = self._copy_without_source(message, dest_id)

            try:
                from src.infrastructure.monitoring.performance.business_metrics import get_business_metrics

                get_business_metrics().record_forward(
                    success=True,
                    preserve_source=bool(preserve_forward_source),
                )
            except Exception as metrics_err:
                logger.debug(f"ä¸šåŠ¡æŒ‡æ ‡ä¸ŠæŠ¥å¤±è´¥ï¼ˆå¿½ç•¥ï¼Œä¸å½±å“ä¸»æµç¨‹ï¼‰: {metrics_err}")

        except Exception as e:
            try:
                from src.infrastructure.monitoring.performance.business_metrics import get_business_metrics

                get_business_metrics().record_forward(
                    success=False,
                    preserve_source=bool(preserve_forward_source),
                    error_type=type(e).__name__,
                )
            except Exception as metrics_err:
                logger.debug(f"ä¸šåŠ¡æŒ‡æ ‡ä¸ŠæŠ¥å¤±è´¥ï¼ˆå¿½ç•¥ï¼Œä¸å½±å“ä¸»æµç¨‹ï¼‰: {metrics_err}")
            raise

        # æ£€æŸ¥ç›®æ ‡é¢‘é“æ˜¯å¦ä¹Ÿæ˜¯ç›‘æ§æºï¼Œå¦‚æœæ˜¯åˆ™æ‰‹åŠ¨è§¦å‘å…¶é…ç½®
        if not record_mode and dest_chat_id and dest_chat_id != "me" and forwarded_message_id:
            text_for_chain = message_text
            self._trigger_dest_monitoring(dest_chat_id, forwarded_message_id, text_for_chain)

        return "success"

    def _forward_with_source(self, message, dest_id):
        """Forward message preserving source

        Returns:
            è½¬å‘åçš„ç¬¬ä¸€æ¡æ¶ˆæ¯IDï¼ˆç”¨äºé“¾å¼è½¬å‘ï¼‰
        """
        logger.debug(f"   ä¿ç•™è½¬å‘æ¥æº")
        forwarded_msg_id = None

        if message.media_group_id:
            try:
                media_group = self.acc.get_media_group(message.chat.id, message.id)
                message_ids = [msg.id for msg in media_group] if media_group else [message.id]
                result = self._execute_with_flood_retry(
                    "è½¬å‘åª’ä½“ç»„",
                    lambda: self.acc.forward_messages(dest_id, message.chat.id, message_ids)
                )
                # forward_messages è¿”å›æ¶ˆæ¯åˆ—è¡¨ï¼Œå–ç¬¬ä¸€ä¸ª
                if result:
                    if isinstance(result, list) and len(result) > 0:
                        forwarded_msg_id = result[0].id if hasattr(result[0], 'id') else result[0]
                    else:
                        forwarded_msg_id = result.id if hasattr(result, 'id') else result
                logger.info(f"   âœ… åª’ä½“ç»„å·²è½¬å‘")
                time.sleep(RATE_LIMIT_DELAY)
            except UnrecoverableError:
                raise
            except Exception as e:
                logger.warning(f"   è½¬å‘åª’ä½“ç»„å¤±è´¥ï¼Œå›é€€åˆ°å•æ¡è½¬å‘: {e}")
                result = self._execute_with_flood_retry(
                    "è½¬å‘å•æ¡æ¶ˆæ¯",
                    lambda: self.acc.forward_messages(dest_id, message.chat.id, message.id)
                )
                if result:
                    if isinstance(result, list) and len(result) > 0:
                        forwarded_msg_id = result[0].id if hasattr(result[0], 'id') else result[0]
                    else:
                        forwarded_msg_id = result.id if hasattr(result, 'id') else result
                logger.info(f"   âœ… æ¶ˆæ¯å·²è½¬å‘ï¼ˆå•æ¡ï¼‰")
                time.sleep(RATE_LIMIT_DELAY)
        else:
            result = self._execute_with_flood_retry(
                "è½¬å‘æ¶ˆæ¯",
                lambda: self.acc.forward_messages(dest_id, message.chat.id, message.id)
            )
            if result:
                if isinstance(result, list) and len(result) > 0:
                    forwarded_msg_id = result[0].id if hasattr(result[0], 'id') else result[0]
                else:
                    forwarded_msg_id = result.id if hasattr(result, 'id') else result
            logger.info(f"   âœ… æ¶ˆæ¯å·²è½¬å‘")
            time.sleep(RATE_LIMIT_DELAY)

        return forwarded_msg_id
    
    def _copy_without_source(self, message, dest_id):
        """Copy message hiding source

        Returns:
            å¤åˆ¶åçš„ç¬¬ä¸€æ¡æ¶ˆæ¯IDï¼ˆç”¨äºé“¾å¼è½¬å‘ï¼‰
        """
        logger.debug(f"   éšè—è½¬å‘æ¥æº")
        forwarded_msg_id = None

        if message.media_group_id:
            try:
                result = self._execute_with_flood_retry(
                    "å¤åˆ¶åª’ä½“ç»„",
                    lambda: self.acc.copy_media_group(dest_id, message.chat.id, message.id)
                )
                # copy_media_group è¿”å›æ¶ˆæ¯åˆ—è¡¨ï¼Œå–ç¬¬ä¸€ä¸ª
                if result:
                    if isinstance(result, list) and len(result) > 0:
                        forwarded_msg_id = result[0].id if hasattr(result[0], 'id') else result[0]
                    else:
                        forwarded_msg_id = result.id if hasattr(result, 'id') else result
                logger.info(f"   âœ… åª’ä½“ç»„å·²å¤åˆ¶ï¼ˆéšè—å¼•ç”¨ï¼‰")
                time.sleep(RATE_LIMIT_DELAY)
            except UnrecoverableError:
                raise
            except Exception as e:
                logger.warning(f"   å¤åˆ¶åª’ä½“ç»„å¤±è´¥ï¼Œå›é€€åˆ°å¤åˆ¶å•æ¡: {e}")
                result = self._execute_with_flood_retry(
                    "å¤åˆ¶å•æ¡æ¶ˆæ¯",
                    lambda: self.acc.copy_message(dest_id, message.chat.id, message.id)
                )
                if result:
                    forwarded_msg_id = result.id if hasattr(result, 'id') else result
                logger.info(f"   âœ… æ¶ˆæ¯å·²å¤åˆ¶ï¼ˆå•æ¡ï¼‰")
                time.sleep(RATE_LIMIT_DELAY)
        else:
            result = self._execute_with_flood_retry(
                "å¤åˆ¶æ¶ˆæ¯",
                lambda: self.acc.copy_message(dest_id, message.chat.id, message.id)
            )
            if result:
                forwarded_msg_id = result.id if hasattr(result, 'id') else result
            logger.info(f"   âœ… æ¶ˆæ¯å·²å¤åˆ¶")
            time.sleep(RATE_LIMIT_DELAY)

        return forwarded_msg_id

    def _get_forwarded_message(self, dest_chat_id: str, forwarded_message_id: int):
        """è·å–è½¬å‘åçš„æ¶ˆæ¯å¯¹è±¡

        Args:
            dest_chat_id: ç›®æ ‡é¢‘é“ ID
            forwarded_message_id: è½¬å‘åçš„æ¶ˆæ¯ ID

        Returns:
            æ¶ˆæ¯å¯¹è±¡ï¼Œå¤±è´¥è¿”å› None
        """
        try:
            dest_id = int(dest_chat_id)
            # ä½¿ç”¨ _execute_with_flood_retry åŒ…è£…ï¼Œæ·»åŠ  FloodWait é‡è¯•æœºåˆ¶
            forwarded_message = self._execute_with_flood_retry(
                "è·å–è½¬å‘åçš„æ¶ˆæ¯",
                lambda: self.acc.get_messages(dest_id, forwarded_message_id)
            )
            if forwarded_message:
                logger.debug(f"   æˆåŠŸè·å–è½¬å‘åçš„æ¶ˆæ¯å¯¹è±¡: chat_id={forwarded_message.chat.id}, message_id={forwarded_message.id}")
            return forwarded_message
        except UnrecoverableError as e:
            logger.warning(f"   âš ï¸ è·å–è½¬å‘åçš„æ¶ˆæ¯å¯¹è±¡å¤±è´¥ï¼ˆä¸å¯æ¢å¤ï¼‰: {e}")
            return None
        except Exception as e:
            logger.error(f"   âŒ è·å–è½¬å‘åçš„æ¶ˆæ¯å¯¹è±¡å¤±è´¥: {e}")
            return None

    def _apply_chain_filters(self, message_text: str, watch_data: dict) -> bool:
        """åº”ç”¨é“¾å¼è½¬å‘çš„è¿‡æ»¤è§„åˆ™

        Args:
            message_text: æ¶ˆæ¯æ–‡æœ¬
            watch_data: ç›‘æ§é…ç½®

        Returns:
            bool: æ˜¯å¦é€šè¿‡è¿‡æ»¤
        """
        task = WatchTask(
            source=str(watch_data.get("source") or ""),
            dest=watch_data.get("dest"),
            whitelist=watch_data.get("whitelist", []),
            blacklist=watch_data.get("blacklist", []),
            whitelist_regex=watch_data.get("whitelist_regex", []),
            blacklist_regex=watch_data.get("blacklist_regex", []),
            preserve_forward_source=bool(watch_data.get("preserve_forward_source", False)),
            forward_mode=watch_data.get("forward_mode", "full"),
            extract_patterns=watch_data.get("extract_patterns", []),
            record_mode=bool(watch_data.get("record_mode", False)),
        )

        if not FilterService.should_forward(task, message_text):
            logger.debug("   â­ï¸ ç›®æ ‡é¢‘é“é…ç½®ï¼šæœªé€šè¿‡è¿‡æ»¤")
            return False

        return True

    def _ensure_peer_cached(self, dest: str) -> bool:
        """ç¡®ä¿ç›®æ ‡ Peer å·²ç¼“å­˜

        Args:
            dest: ç›®æ ‡ ID

        Returns:
            bool: æ˜¯å¦ç¼“å­˜æˆåŠŸ
        """
        from bot.services.peer_cache import cache_peer_if_needed
        from bot.utils.peer import is_dest_cached

        if is_dest_cached(dest):
            logger.debug(f"      ä¸‹ä¸€çº§ç›®æ ‡Peerå·²ç¼“å­˜: {dest}")
            return True

        logger.debug(f"      å°è¯•ç¼“å­˜ä¸‹ä¸€çº§ç›®æ ‡Peer: {dest}")
        if cache_peer_if_needed(self.acc, int(dest), "ä¸‹ä¸€çº§ç›®æ ‡"):
            return True

        logger.warning(f"   âš ï¸ ä¸‹ä¸€çº§ç›®æ ‡Peerç¼“å­˜å¤±è´¥: {dest}")
        logger.warning(f"      ğŸ’¡ æç¤ºï¼šå¦‚æœç›®æ ‡æ˜¯ç§èŠç”¨æˆ·ï¼Œè¯·ç¡®ä¿è¯¥ç”¨æˆ·å·²ä¸è´¦å·å»ºç«‹è¿‡å¯¹è¯")
        logger.warning(f"      ğŸ’¡ å¯ä»¥è®©è¯¥ç”¨æˆ·å‘è´¦å·å‘é€ä¸€æ¡æ¶ˆæ¯ï¼Œç„¶åé‡å¯Bot")
        return False

    def _process_chain_config(self, forwarded_message, check_user_id: str, dest_chat_id_str: str,
                              message_text: str, watch_data: dict) -> None:
        """å¤„ç†å•ä¸ªé“¾å¼è½¬å‘é…ç½®

        Args:
            forwarded_message: è½¬å‘åçš„æ¶ˆæ¯å¯¹è±¡
            check_user_id: ç”¨æˆ· ID
            dest_chat_id_str: ç›®æ ‡é¢‘é“ ID
            message_text: æ¶ˆæ¯æ–‡æœ¬
            watch_data: ç›‘æ§é…ç½®
        """
        check_record_mode = watch_data.get("record_mode", False)
        check_dest = watch_data.get("dest")
        check_forward_mode = watch_data.get("forward_mode", "full")
        check_extract_patterns = watch_data.get("extract_patterns", [])

        # è®°å½•æ¨¡å¼
        if check_record_mode:
            logger.info(f"   ğŸ“ ç›®æ ‡é¢‘é“é…ç½®ï¼šè®°å½•æ¨¡å¼")
            try:
                self._handle_record_mode(
                    forwarded_message, check_user_id, dest_chat_id_str,
                    message_text, check_forward_mode, check_extract_patterns
                )
            except Exception as e:
                logger.error(f"   âŒ ç›®æ ‡é¢‘é“è®°å½•å¤±è´¥: {e}", exc_info=True)

        # è½¬å‘æ¨¡å¼
        if check_dest and check_dest != "me":
            logger.info(f"   ğŸ“¤ ç›®æ ‡é¢‘é“é…ç½®ï¼šè½¬å‘åˆ° {check_dest}")
            logger.debug(f"      è½¬å‘æ¨¡å¼: {check_forward_mode}")

            if not self._ensure_peer_cached(str(check_dest)):
                return

            try:
                check_preserve_source = watch_data.get("preserve_forward_source", False)
                self._handle_forward_mode(
                    forwarded_message, check_dest, message_text,
                    check_forward_mode, check_extract_patterns,
                    check_preserve_source, False
                )
            except Exception as e:
                logger.error(f"   âŒ ç›®æ ‡é¢‘é“è½¬å‘å¤±è´¥: {e}", exc_info=True)

    def _trigger_dest_monitoring(self, dest_chat_id, forwarded_message_id, message_text):
        """æ‰‹åŠ¨è§¦å‘ç›®æ ‡é¢‘é“çš„ç›‘æ§é…ç½®å¤„ç†

        å½“ç›®æ ‡é¢‘é“ä¹Ÿæ˜¯ç›‘æ§æºæ—¶ï¼Œè½¬å‘åˆ°è¯¥é¢‘é“çš„æ¶ˆæ¯ä¸ä¼šè‡ªåŠ¨è§¦å‘ç›‘æ§
        ï¼ˆå› ä¸º copy_message ä¸è§¦å‘ outgoing äº‹ä»¶ï¼‰ï¼Œæ‰€ä»¥éœ€è¦æ‰‹åŠ¨è§¦å‘

        Args:
            dest_chat_id: ç›®æ ‡é¢‘é“ ID
            forwarded_message_id: è½¬å‘åçš„æ¶ˆæ¯ ID
            message_text: æ¶ˆæ¯æ–‡æœ¬å†…å®¹
        """
        # ä½¿ç”¨ WatchService è·å–é…ç½®
        watch_service = get_watch_service()

        dest_chat_id_str = str(dest_chat_id)
        monitored_sources = watch_service.get_monitored_sources()

        # æ£€æŸ¥ç›®æ ‡æ˜¯å¦æ˜¯ç›‘æ§æº
        if dest_chat_id_str not in monitored_sources:
            return

        logger.info(f"ğŸ”„ ç›®æ ‡é¢‘é“ {dest_chat_id} ä¹Ÿæ˜¯ç›‘æ§æºï¼Œæ‰‹åŠ¨è§¦å‘å…¶é…ç½®å¤„ç†...")
        logger.debug(f"   è½¬å‘åçš„æ¶ˆæ¯ID: {forwarded_message_id}")

        # è·å–è½¬å‘åçš„æ¶ˆæ¯å¯¹è±¡
        forwarded_message = self._get_forwarded_message(dest_chat_id_str, forwarded_message_id)
        if not forwarded_message:
            logger.warning(f"   âš ï¸ æ— æ³•è·å–è½¬å‘åçš„æ¶ˆæ¯å¯¹è±¡ï¼Œè·³è¿‡é“¾å¼è½¬å‘")
            return

        matched_configs = 0
        tasks_for_source = watch_service.get_tasks_for_source(dest_chat_id_str)

        for entry in tasks_for_source:
            if not isinstance(entry, (tuple, list)):
                continue

            if len(entry) == 3:
                check_user_id, check_watch_key, check_task = entry
            elif len(entry) == 2:
                check_user_id, check_task = entry
                check_watch_key = ""
            else:
                continue

            if hasattr(check_task, "to_dict"):
                check_watch_data = check_task.to_dict()
            elif isinstance(check_task, dict):
                check_watch_data = check_task
            else:
                continue

            matched_configs += 1
            check_dest = check_watch_data.get("dest")
            check_record_mode = check_watch_data.get("record_mode", False)

            # è·³è¿‡"è½¬å‘åˆ°è‡ªå·±"çš„é…ç½®ï¼Œé¿å…æ— é™å¾ªç¯
            if (
                not check_record_mode
                and check_dest is not None
                and str(check_dest) == dest_chat_id_str
            ):
                logger.debug(f"   â­ï¸ è·³è¿‡è½¬å‘åˆ°è‡ªå·±çš„é…ç½®ï¼Œé¿å…å¾ªç¯")
                continue

            logger.info(
                f"   âœ… æ‰¾åˆ°ç›®æ ‡é¢‘é“çš„é…ç½® #{matched_configs}: user={check_user_id}, key={check_watch_key}, "
                f"mode={'è®°å½•' if check_record_mode else 'è½¬å‘åˆ° ' + str(check_dest)}"
            )

            # åº”ç”¨è¿‡æ»¤è§„åˆ™
            if not self._apply_chain_filters(message_text, check_watch_data):
                continue

            logger.info(f"   ğŸ¯ ç›®æ ‡é¢‘é“é…ç½®ï¼šé€šè¿‡è¿‡æ»¤è§„åˆ™")

            # å¤„ç†é…ç½®
            self._process_chain_config(
                forwarded_message,
                str(check_user_id),
                dest_chat_id_str,
                message_text,
                check_watch_data,
            )

        if matched_configs == 0:
            logger.debug(f"   â„¹ï¸ ç›®æ ‡é¢‘é“ {dest_chat_id} æ²¡æœ‰åŒ¹é…çš„é…ç½®")
        else:
            logger.info(f"   ğŸ“Š é“¾å¼è½¬å‘å®Œæˆ: å…±å¤„ç† {matched_configs} ä¸ªé…ç½®")

    def stop(self):
        """åœæ­¢å·¥ä½œçº¿ç¨‹"""
        self.running = False
        logger.info("ğŸ›‘ æ­£åœ¨åœæ­¢æ¶ˆæ¯å·¥ä½œçº¿ç¨‹...")
