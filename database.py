import sqlite3
import bcrypt
from datetime import datetime
from zoneinfo import ZoneInfo
import os
import json
import logging
import re
from contextlib import contextmanager
from constants import DB_DEDUP_WINDOW

logger = logging.getLogger(__name__)

# è®¾ç½®ä¸­å›½æ—¶åŒº
CHINA_TZ = ZoneInfo("Asia/Shanghai")

# æ•°æ®ç›®å½• - ç‹¬ç«‹å­˜å‚¨ï¼Œé˜²æ­¢æ›´æ–°æ—¶ä¸¢å¤±
DEFAULT_DATA_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), 'data'))
DATA_DIR = os.environ.get('DATA_DIR', DEFAULT_DATA_DIR)
DATABASE_FILE = os.path.join(DATA_DIR, 'notes.db')


@contextmanager
def get_db_connection():
    """Database connection context manager"""
    conn = sqlite3.connect(DATABASE_FILE)
    try:
        yield conn
        conn.commit()
    except Exception:
        conn.rollback()
        raise
    finally:
        conn.close()

def init_database():
    """åˆå§‹åŒ–æ•°æ®åº“ï¼Œåˆ›å»ºå¿…è¦çš„è¡¨"""
    try:
        print("=" * 50)
        print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–æ•°æ®åº“...")
        print(f"ğŸ“ æ•°æ®ç›®å½•: {DATA_DIR}")
        print(f"ğŸ’¾ æ•°æ®åº“è·¯å¾„: {DATABASE_FILE}")
        
        # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
        os.makedirs(DATA_DIR, exist_ok=True)
        print(f"âœ… æ•°æ®ç›®å½•å·²ç¡®è®¤å­˜åœ¨")
        
        conn = sqlite3.connect(DATABASE_FILE)
        cursor = conn.cursor()
        
        # åˆ›å»ºç¬”è®°è¡¨
        print("ğŸ“ æ­£åœ¨åˆ›å»º notes è¡¨...")
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS notes (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id INTEGER NOT NULL,
                source_chat_id TEXT NOT NULL,
                source_name TEXT,
                message_text TEXT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                media_type TEXT,
                media_path TEXT,
                media_paths TEXT,
                media_group_id TEXT,
                magnet_link TEXT
            )
        ''')
        print("âœ… notes è¡¨åˆ›å»ºæˆåŠŸ")
        
        # æ£€æŸ¥å¹¶æ·»åŠ  media_paths åˆ—ï¼ˆè¿ç§»æ—§æ•°æ®åº“ï¼‰
        print("ğŸ”„ æ£€æŸ¥ media_paths åˆ—æ˜¯å¦å­˜åœ¨...")
        cursor.execute("PRAGMA table_info(notes)")
        columns = [column[1] for column in cursor.fetchall()]
        if 'media_paths' not in columns:
            print("â• æ·»åŠ  media_paths åˆ—...")
            cursor.execute("ALTER TABLE notes ADD COLUMN media_paths TEXT")
            conn.commit()
            print("âœ… media_paths åˆ—æ·»åŠ æˆåŠŸ")
        else:
            print("âœ… media_paths åˆ—å·²å­˜åœ¨")
        
        # æ£€æŸ¥å¹¶æ·»åŠ  media_group_id åˆ—ï¼ˆè¿ç§»æ—§æ•°æ®åº“ï¼‰
        print("ğŸ”„ æ£€æŸ¥ media_group_id åˆ—æ˜¯å¦å­˜åœ¨...")
        cursor.execute("PRAGMA table_info(notes)")
        columns = [column[1] for column in cursor.fetchall()]
        if 'media_group_id' not in columns:
            print("â• æ·»åŠ  media_group_id åˆ—...")
            cursor.execute("ALTER TABLE notes ADD COLUMN media_group_id TEXT")
            conn.commit()
            print("âœ… media_group_id åˆ—æ·»åŠ æˆåŠŸ")
        else:
            print("âœ… media_group_id åˆ—å·²å­˜åœ¨")

        # æ£€æŸ¥å¹¶æ·»åŠ  magnet_link åˆ—ï¼ˆè¿ç§»æ—§æ•°æ®åº“ï¼‰
        print("ğŸ”„ æ£€æŸ¥ magnet_link åˆ—æ˜¯å¦å­˜åœ¨...")
        cursor.execute("PRAGMA table_info(notes)")
        columns = [column[1] for column in cursor.fetchall()]
        if 'magnet_link' not in columns:
            print("â• æ·»åŠ  magnet_link åˆ—...")
            cursor.execute("ALTER TABLE notes ADD COLUMN magnet_link TEXT")
            conn.commit()
            print("âœ… magnet_link åˆ—æ·»åŠ æˆåŠŸ")
        else:
            print("âœ… magnet_link åˆ—å·²å­˜åœ¨")

        # æ£€æŸ¥å¹¶æ·»åŠ  filename åˆ—ï¼ˆç”¨äºå­˜å‚¨æ ¡å‡†åçš„æ–‡ä»¶åï¼‰
        print("ğŸ”„ æ£€æŸ¥ filename åˆ—æ˜¯å¦å­˜åœ¨...")
        cursor.execute("PRAGMA table_info(notes)")
        columns = [column[1] for column in cursor.fetchall()]
        if 'filename' not in columns:
            print("â• æ·»åŠ  filename åˆ—...")
            cursor.execute("ALTER TABLE notes ADD COLUMN filename TEXT")
            conn.commit()
            print("âœ… filename åˆ—æ·»åŠ æˆåŠŸ")
        else:
            print("âœ… filename åˆ—å·²å­˜åœ¨")

        # æ£€æŸ¥å¹¶æ·»åŠ  is_favorite åˆ—ï¼ˆæ”¶è—åŠŸèƒ½ï¼‰
        print("ğŸ”„ æ£€æŸ¥ is_favorite åˆ—æ˜¯å¦å­˜åœ¨...")
        cursor.execute("PRAGMA table_info(notes)")
        columns = [column[1] for column in cursor.fetchall()]
        if 'is_favorite' not in columns:
            print("â• æ·»åŠ  is_favorite åˆ—...")
            cursor.execute("ALTER TABLE notes ADD COLUMN is_favorite INTEGER DEFAULT 0")
            conn.commit()
            print("âœ… is_favorite åˆ—æ·»åŠ æˆåŠŸ")
        else:
            print("âœ… is_favorite åˆ—å·²å­˜åœ¨")

        # åˆ›å»ºç”¨æˆ·è¡¨
        print("ğŸ‘¤ æ­£åœ¨åˆ›å»º users è¡¨...")
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS users (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                username TEXT UNIQUE NOT NULL,
                password_hash TEXT NOT NULL
            )
        ''')
        print("âœ… users è¡¨åˆ›å»ºæˆåŠŸ")

        # åˆ›å»ºæ ¡å‡†ä»»åŠ¡è¡¨
        print("ğŸ”§ æ­£åœ¨åˆ›å»º calibration_tasks è¡¨...")
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS calibration_tasks (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                note_id INTEGER NOT NULL,
                magnet_hash TEXT NOT NULL,
                status TEXT NOT NULL DEFAULT 'pending',
                retry_count INTEGER DEFAULT 0,
                last_attempt DATETIME,
                next_attempt DATETIME NOT NULL,
                error_message TEXT,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (note_id) REFERENCES notes(id) ON DELETE CASCADE
            )
        ''')
        print("âœ… calibration_tasks è¡¨åˆ›å»ºæˆåŠŸ")

        # åˆ›å»ºç´¢å¼•ä»¥æé«˜æŸ¥è¯¢æ•ˆç‡
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_calibration_status
            ON calibration_tasks(status, next_attempt)
        ''')
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_calibration_note
            ON calibration_tasks(note_id)
        ''')

        # åˆ›å»ºè‡ªåŠ¨æ ¡å‡†é…ç½®è¡¨
        print("âš™ï¸ æ­£åœ¨åˆ›å»º auto_calibration_config è¡¨...")
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS auto_calibration_config (
                id INTEGER PRIMARY KEY CHECK (id = 1),
                enabled BOOLEAN DEFAULT 0,
                filter_mode TEXT DEFAULT 'empty_only',
                first_delay INTEGER DEFAULT 600,
                retry_delay_1 INTEGER DEFAULT 3600,
                retry_delay_2 INTEGER DEFAULT 14400,
                retry_delay_3 INTEGER DEFAULT 28800,
                max_retries INTEGER DEFAULT 3,
                concurrent_limit INTEGER DEFAULT 5,
                timeout_per_magnet INTEGER DEFAULT 30,
                batch_timeout INTEGER DEFAULT 300
            )
        ''')

        # æ’å…¥é»˜è®¤é…ç½®
        cursor.execute('''
            INSERT OR IGNORE INTO auto_calibration_config (id, enabled, filter_mode)
            VALUES (1, 0, 'empty_only')
        ''')
        print("âœ… auto_calibration_config è¡¨åˆ›å»ºæˆåŠŸ")
        
        # åˆ›å»ºé»˜è®¤ç®¡ç†å‘˜è´¦æˆ· (admin/admin)
        try:
            print("ğŸ” æ­£åœ¨åˆ›å»ºé»˜è®¤ç®¡ç†å‘˜è´¦æˆ·...")
            password_hash = bcrypt.hashpw('admin'.encode('utf-8'), bcrypt.gensalt()).decode('utf-8')
            cursor.execute('INSERT INTO users (username, password_hash) VALUES (?, ?)', ('admin', password_hash))
            print("âœ… é»˜è®¤ç®¡ç†å‘˜è´¦æˆ·åˆ›å»ºæˆåŠŸ (admin/admin)")
        except sqlite3.IntegrityError:
            # ç®¡ç†å‘˜è´¦æˆ·å·²å­˜åœ¨
            print("â„¹ï¸  ç®¡ç†å‘˜è´¦æˆ·å·²å­˜åœ¨ï¼Œè·³è¿‡åˆ›å»º")
        
        conn.commit()
        
        # éªŒè¯è¡¨æ˜¯å¦åˆ›å»ºæˆåŠŸ
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
        tables = [row[0] for row in cursor.fetchall()]
        print(f"ğŸ“Š æ•°æ®åº“ä¸­çš„è¡¨: {', '.join(tables)}")
        
        # æ£€æŸ¥ notes è¡¨ä¸­çš„è®°å½•æ•°
        cursor.execute("SELECT COUNT(*) FROM notes")
        notes_count = cursor.fetchone()[0]
        print(f"ğŸ“ notes è¡¨ä¸­ç°æœ‰è®°å½•æ•°: {notes_count}")
        
        conn.close()
        print("âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆï¼")
        print("=" * 50)
        
    except Exception as e:
        print("=" * 50)
        print(f"âŒ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥ï¼")
        print(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
        print(f"é”™è¯¯ä¿¡æ¯: {str(e)}")
        print("=" * 50)
        raise

def _validate_and_convert_params(user_id, source_chat_id):
    """Validate and convert note parameters"""
    if user_id is None:
        raise ValueError("user_id ä¸èƒ½ä¸º None")
    if source_chat_id is None:
        raise ValueError("source_chat_id ä¸èƒ½ä¸º None")
    
    # ç¡®ä¿ user_id æ˜¯æ•´æ•°
    if not isinstance(user_id, int):
        try:
            user_id = int(user_id)
        except (ValueError, TypeError) as e:
            raise ValueError(f"user_id å¿…é¡»æ˜¯æ•´æ•°æˆ–å¯è½¬æ¢ä¸ºæ•´æ•°çš„å€¼: {user_id}") from e
    
    # ç¡®ä¿ source_chat_id æ˜¯å­—ç¬¦ä¸²
    if not isinstance(source_chat_id, str):
        source_chat_id = str(source_chat_id)
    
    return user_id, source_chat_id


def _check_duplicate_media_group(cursor, user_id, source_chat_id, media_group_id):
    """Check for duplicate media groups"""
    cursor.execute(
        "SELECT id FROM notes WHERE user_id=? AND source_chat_id=? AND media_group_id=? LIMIT 1",
        (user_id, source_chat_id, media_group_id)
    )
    existing = cursor.fetchone()
    if existing:
        existing_id = existing[0]
        logger.debug(f"åª’ä½“ç»„å·²å­˜åœ¨ï¼Œè·³è¿‡é‡å¤ä¿å­˜ (existing_id={existing_id})")
        return existing_id
    return None


def _check_duplicate_message(cursor, user_id, source_chat_id, message_text):
    """Check for duplicate messages within time window"""
    cursor.execute(f"""
        SELECT id FROM notes
        WHERE user_id=? AND source_chat_id=? AND message_text=?
        AND datetime(timestamp) > datetime('now', '-{DB_DEDUP_WINDOW} seconds')
        LIMIT 1
    """, (user_id, source_chat_id, message_text))
    existing = cursor.fetchone()
    if existing:
        existing_id = existing[0]
        logger.debug(f"æ¶ˆæ¯åœ¨{DB_DEDUP_WINDOW}ç§’å†…å·²ä¿å­˜ï¼Œè·³è¿‡é‡å¤ (existing_id={existing_id})")
        return existing_id
    return None


def _extract_magnet_link(message_text):
    """ä»æ¶ˆæ¯æ–‡æœ¬ä¸­æå–ç£åŠ›é“¾æ¥"""
    if not message_text:
        return None

    # åŒ¹é…å®Œæ•´çš„ç£åŠ›é“¾æ¥æ ¼å¼: magnet:?xt=urn:btih:...ï¼ˆåŒ…å«æ‰€æœ‰å‚æ•°ï¼‰
    # åŒ¹é…åˆ°æ¢è¡Œã€ç«–çº¿æˆ–å­—ç¬¦ä¸²ç»“æŸä¸ºæ­¢ï¼ˆå…è®¸ç©ºæ ¼ï¼Œå› ä¸ºdnå‚æ•°ä¸­å¯èƒ½æœ‰ç©ºæ ¼ï¼‰
    magnet_pattern = r'magnet:\?xt=urn:btih:[a-zA-Z0-9]+(?:[&?][^\n\r|]*)?'
    match = re.search(magnet_pattern, message_text, re.IGNORECASE)

    if match:
        magnet_link = match.group(0).rstrip()

        # æ£€æµ‹æ˜¯å¦æœ‰ dn å‚æ•°
        if '&dn=' not in magnet_link and '?dn=' not in magnet_link:
            # æå–å¼€å¤´è‡³ç¬¬ä¸€ä¸ª # ä¹‹å‰çš„å†…å®¹ä½œä¸º dn
            hash_pos = message_text.find('#')
            dn_text = message_text[:hash_pos].rstrip() if hash_pos != -1 else message_text.rstrip()

            if dn_text:
                # URLç¼–ç dnå‚æ•°ï¼Œä¿ç•™ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦
                from urllib.parse import quote
                magnet_link += f'&dn={quote(dn_text)}'

        return magnet_link
    return None


def add_note(user_id, source_chat_id, source_name, message_text, media_type=None, media_path=None, media_paths=None, media_group_id=None):
    """æ·»åŠ ä¸€æ¡ç¬”è®°è®°å½•"""
    try:
        logger.debug(f"å¼€å§‹ä¿å­˜ç¬”è®°: user_id={user_id}, source={source_chat_id}, media_type={media_type}")

        # éªŒè¯å’Œè½¬æ¢å‚æ•°
        user_id, source_chat_id = _validate_and_convert_params(user_id, source_chat_id)

        with get_db_connection() as conn:
            cursor = conn.cursor()

            # Check for duplicate media groups
            if media_group_id:
                existing_id = _check_duplicate_media_group(cursor, user_id, source_chat_id, media_group_id)
                if existing_id:
                    return existing_id

            # Check for duplicate messages
            if message_text and not media_group_id:
                existing_id = _check_duplicate_message(cursor, user_id, source_chat_id, message_text)
                if existing_id:
                    return existing_id

            # Prepare media paths JSON
            media_paths_json = None
            if media_paths:
                if media_path is None:
                    media_path = media_paths[0]
                media_paths_json = json.dumps(media_paths, ensure_ascii=False)

            # Extract magnet link from message text
            magnet_link = _extract_magnet_link(message_text)

            # Generate China timezone timestamp
            china_timestamp = datetime.now(CHINA_TZ).strftime('%Y-%m-%d %H:%M:%S')

            # Insert note (filenameç•™ç©ºï¼Œç”±è‡ªåŠ¨æ ¡å‡†å¡«å……)
            cursor.execute('''
                INSERT INTO notes (user_id, source_chat_id, source_name, message_text, timestamp, media_type, media_path, media_paths, media_group_id, magnet_link, filename)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (user_id, source_chat_id, source_name, message_text, china_timestamp, media_type, media_path, media_paths_json, media_group_id, magnet_link, None))

            note_id = cursor.lastrowid
            logger.info(f"âœ… ç¬”è®°ä¿å­˜æˆåŠŸï¼note_id={note_id}, magnet_link={'æœ‰' if magnet_link else 'æ— '}")

        # äº‹åŠ¡å·²æäº¤ï¼Œç°åœ¨å¯ä»¥å®‰å…¨åœ°æ·»åŠ åˆ°æ ¡å‡†é˜Ÿåˆ—
        # è‡ªåŠ¨æ·»åŠ åˆ°æ ¡å‡†é˜Ÿåˆ—ï¼ˆå¦‚æœå¯ç”¨äº†è‡ªåŠ¨æ ¡å‡†ï¼‰
        logger.info(f"ğŸ“‹ æ£€æŸ¥æ ¡å‡†æ¡ä»¶: note_id={note_id}, has_magnet={bool(magnet_link)}")
        if note_id and magnet_link:
            try:
                # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯ä¾èµ–
                from bot.services.calibration_manager import get_calibration_manager
                manager = get_calibration_manager()
                is_enabled = manager.is_enabled()
                logger.info(f"ğŸ”§ æ ¡å‡†ç®¡ç†å™¨å·²åŠ è½½: enabled={is_enabled}")
                if is_enabled:
                    # åœ¨äº‹åŠ¡å¤–å¼‚æ­¥æ·»åŠ ï¼Œé¿å…é˜»å¡
                    import threading
                    logger.info(f"ğŸš€ å¯åŠ¨æ ¡å‡†ä»»åŠ¡çº¿ç¨‹: note_id={note_id}")
                    threading.Thread(
                        target=manager.add_note_to_calibration_queue,
                        args=(note_id,),
                        daemon=True
                    ).start()
                    logger.info(f"âœ… æ ¡å‡†çº¿ç¨‹å·²å¯åŠ¨: note_id={note_id}")
                else:
                    logger.info(f"â­ï¸ è‡ªåŠ¨æ ¡å‡†æœªå¯ç”¨ï¼Œè·³è¿‡ note_id={note_id}")
            except Exception as e:
                logger.error(f"âŒ æ·»åŠ åˆ°æ ¡å‡†é˜Ÿåˆ—å¤±è´¥: {e}", exc_info=True)
        else:
            logger.info(f"â­ï¸ è·³è¿‡æ ¡å‡†: note_id={note_id}, magnet_link={magnet_link[:50] if magnet_link else 'None'}")

        return note_id

    except sqlite3.Error as e:
        logger.error(f"SQLite é”™è¯¯: {type(e).__name__}: {e}")
        raise
    except Exception as e:
        logger.error(f"ä¿å­˜ç¬”è®°å¤±è´¥: {type(e).__name__}: {e}")
        raise

def _parse_media_paths(note):
    """Parse media paths from JSON string"""
    if note.get('media_paths'):
        try:
            note['media_paths'] = json.loads(note['media_paths'])
        except (json.JSONDecodeError, TypeError):
            note['media_paths'] = []
    else:
        note['media_paths'] = []
    
    # Fallback: if media_paths is empty but media_path exists
    if not note['media_paths'] and note.get('media_path'):
        note['media_paths'] = [note['media_path']]
    
    return note


def get_notes(user_id=None, source_chat_id=None, search_query=None, date_from=None, date_to=None, favorite_only=False, limit=50, offset=0):
    """è·å–ç¬”è®°åˆ—è¡¨"""
    with get_db_connection() as conn:
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()

        query = 'SELECT * FROM notes WHERE 1=1'
        params = []

        if user_id:
            query += ' AND user_id = ?'
            params.append(user_id)

        if source_chat_id:
            query += ' AND source_chat_id = ?'
            params.append(source_chat_id)

        if search_query:
            query += ' AND (message_text LIKE ? OR source_name LIKE ?)'
            search_pattern = f'%{search_query}%'
            params.extend([search_pattern, search_pattern])

        if date_from:
            query += ' AND DATE(timestamp) >= ?'
            params.append(date_from)

        if date_to:
            query += ' AND DATE(timestamp) <= ?'
            params.append(date_to)

        if favorite_only:
            query += ' AND is_favorite = 1'

        query += ' ORDER BY timestamp DESC LIMIT ? OFFSET ?'
        params.extend([limit, offset])

        cursor.execute(query, params)
        notes = [_parse_media_paths(dict(row)) for row in cursor.fetchall()]
        return notes

def get_note_count(user_id=None, source_chat_id=None, search_query=None, date_from=None, date_to=None, favorite_only=False):
    """è·å–ç¬”è®°æ€»æ•°"""
    with get_db_connection() as conn:
        cursor = conn.cursor()

        query = 'SELECT COUNT(*) FROM notes WHERE 1=1'
        params = []

        if user_id:
            query += ' AND user_id = ?'
            params.append(user_id)

        if source_chat_id:
            query += ' AND source_chat_id = ?'
            params.append(source_chat_id)
        
        if search_query:
            query += ' AND (message_text LIKE ? OR source_name LIKE ?)'
            search_pattern = f'%{search_query}%'
            params.extend([search_pattern, search_pattern])
        
        if date_from:
            query += ' AND DATE(timestamp) >= ?'
            params.append(date_from)
        
        if date_to:
            query += ' AND DATE(timestamp) <= ?'
            params.append(date_to)

        if favorite_only:
            query += ' AND is_favorite = 1'

        cursor.execute(query, params)
        return cursor.fetchone()[0]

def get_sources(user_id=None):
    """è·å–æ‰€æœ‰æ¥æºçš„åˆ—è¡¨"""
    with get_db_connection() as conn:
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        query = 'SELECT DISTINCT source_chat_id, source_name FROM notes WHERE 1=1'
        params = []
        
        if user_id:
            query += ' AND user_id = ?'
            params.append(user_id)
        
        cursor.execute(query, params)
        return [dict(row) for row in cursor.fetchall()]


def verify_user(username, password):
    """éªŒè¯ç”¨æˆ·ç™»å½•"""
    with get_db_connection() as conn:
        cursor = conn.cursor()
        cursor.execute('SELECT password_hash FROM users WHERE username = ?', (username,))
        result = cursor.fetchone()
        
        if result:
            password_hash = result[0]
            return bcrypt.checkpw(password.encode('utf-8'), password_hash.encode('utf-8'))
        return False


def update_password(username, new_password):
    """æ›´æ–°ç”¨æˆ·å¯†ç """
    with get_db_connection() as conn:
        cursor = conn.cursor()
        password_hash = bcrypt.hashpw(new_password.encode('utf-8'), bcrypt.gensalt()).decode('utf-8')
        cursor.execute('UPDATE users SET password_hash = ? WHERE username = ?', (password_hash, username))


def get_note_by_id(note_id):
    """æ ¹æ®IDè·å–å•æ¡ç¬”è®°"""
    with get_db_connection() as conn:
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        cursor.execute('SELECT * FROM notes WHERE id = ?', (note_id,))
        row = cursor.fetchone()
        
        if row:
            return _parse_media_paths(dict(row))
        return None


def update_note(note_id, message_text):
    """æ›´æ–°ç¬”è®°å†…å®¹"""
    with get_db_connection() as conn:
        cursor = conn.cursor()
        cursor.execute('UPDATE notes SET message_text = ? WHERE id = ?', (message_text, note_id))
        return cursor.rowcount > 0


def update_magnet_link(note_id, magnet_link):
    """æ›´æ–°ç£åŠ›é“¾æ¥"""
    with get_db_connection() as conn:
        cursor = conn.cursor()
        cursor.execute('UPDATE notes SET magnet_link = ? WHERE id = ?', (magnet_link, note_id))
        return cursor.rowcount > 0


def update_note_with_calibrated_dns(note_id, calibrated_results):
    """æ ¡å‡†åæ›´æ–°ç¬”è®°ï¼šåŒæ—¶æ›´æ–°å¤šä¸ªç£åŠ›é“¾æ¥çš„dnå‚æ•°

    Args:
        note_id: ç¬”è®°ID
        calibrated_results: æ ¡å‡†ç»“æœåˆ—è¡¨ [{'info_hash': ..., 'old_magnet': ..., 'filename': ..., 'success': bool}, ...]

    Returns:
        bool: æ˜¯å¦æ›´æ–°æˆåŠŸ
    """
    import re
    from urllib.parse import quote

    with get_db_connection() as conn:
        cursor = conn.cursor()

        # è·å–å½“å‰ç¬”è®°å†…å®¹
        cursor.execute('SELECT message_text, magnet_link FROM notes WHERE id = ?', (note_id,))
        row = cursor.fetchone()
        if not row:
            return False

        message_text, old_magnet = row
        updated_text = message_text

        # æ›´æ–°ç¬”è®°æ–‡æœ¬ä¸­çš„æ¯ä¸ªç£åŠ›é“¾æ¥
        if message_text:
            for result in calibrated_results:
                if not result.get('success'):
                    continue  # è·³è¿‡å¤±è´¥çš„æ ¡å‡†

                info_hash = result['info_hash']
                filename = result.get('filename', '')

                # æ„å»ºæ–°çš„ç£åŠ›é“¾æ¥ï¼ˆä½¿ç”¨åŸå§‹æ–‡ä»¶åï¼Œä¸ç¼–ç ï¼‰
                new_magnet = f"magnet:?xt=urn:btih:{info_hash}&dn={filename}"

                # åœ¨æ–‡æœ¬ä¸­æŸ¥æ‰¾å¹¶æ›¿æ¢è¯¥ç£åŠ›é“¾æ¥
                # åŒ¹é…: magnet:?xt=urn:btih:{hash} åé¢è·Ÿä»»æ„å‚æ•°ç›´åˆ°æ¢è¡Œæˆ–ç»“æŸ
                magnet_pattern = rf'magnet:\?xt=urn:btih:{re.escape(info_hash)}(?:[&?][^\n\r]*)?'

                # æ›¿æ¢æ‰¾åˆ°çš„ç£åŠ›é“¾æ¥
                updated_text = re.sub(magnet_pattern, new_magnet, updated_text, flags=re.IGNORECASE)

        # æ›´æ–°magnet_linkå­—æ®µï¼ˆä½¿ç”¨ç¬¬ä¸€ä¸ªæˆåŠŸæ ¡å‡†çš„ç£åŠ›é“¾æ¥ï¼‰
        new_magnet_link = old_magnet
        new_filename = None
        for result in calibrated_results:
            if result.get('success'):
                info_hash = result['info_hash']
                filename = result.get('filename', '')
                old_magnet_for_db = result['old_magnet']

                # ç§»é™¤æ—§çš„ dn å‚æ•°
                new_magnet_base = re.sub(r'[&?]dn=[^&]*', '', old_magnet_for_db)

                # æ·»åŠ URLç¼–ç çš„dnå‚æ•°ï¼ˆç”¨äºå­˜å‚¨ï¼‰
                encoded_filename = quote(filename) if filename else ""
                new_magnet_link = f"{new_magnet_base}&dn={encoded_filename}"
                new_filename = filename  # ä¿å­˜ç”¨äºæ›´æ–°filenameå­—æ®µ
                break  # åªä½¿ç”¨ç¬¬ä¸€ä¸ªæˆåŠŸçš„

        # æ›´æ–°æ•°æ®åº“ï¼ˆåŒ…æ‹¬filenameå­—æ®µï¼‰
        cursor.execute(
            'UPDATE notes SET message_text = ?, magnet_link = ?, filename = ? WHERE id = ?',
            (updated_text, new_magnet_link, new_filename, note_id)
        )

        return cursor.rowcount > 0


def update_note_with_calibrated_dn(note_id, new_magnet_link, filename):
    """æ ¡å‡†åæ›´æ–°ç¬”è®°ï¼šåŒæ—¶æ›´æ–°ç£åŠ›é“¾æ¥å’Œç¬”è®°æ–‡æœ¬ä¸­çš„ dn å‚æ•°ï¼ˆä¿ç•™å‘åå…¼å®¹ï¼‰

    Args:
        note_id: ç¬”è®°ID
        new_magnet_link: æ–°çš„ç£åŠ›é“¾æ¥ï¼ˆå·²åŒ…å«URLç¼–ç çš„dnï¼Œç”¨äºæ•°æ®åº“å­˜å‚¨ï¼‰
        filename: æ ¡å‡†åçš„åŸå§‹æ–‡ä»¶åï¼ˆæœªç¼–ç ï¼Œç”¨äºç¬”è®°æ–‡æœ¬æ˜¾ç¤ºï¼‰

    Returns:
        bool: æ˜¯å¦æ›´æ–°æˆåŠŸ
    """
    import re

    with get_db_connection() as conn:
        cursor = conn.cursor()

        # è·å–å½“å‰ç¬”è®°å†…å®¹
        cursor.execute('SELECT message_text, magnet_link FROM notes WHERE id = ?', (note_id,))
        row = cursor.fetchone()
        if not row:
            return False

        message_text, old_magnet = row

        # æ›´æ–°ç¬”è®°æ–‡æœ¬ä¸­çš„ç£åŠ›é“¾æ¥ï¼ˆä½¿ç”¨åŸå§‹æ–‡ä»¶åï¼Œä¸ç¼–ç ï¼‰
        updated_text = message_text

        if message_text:
            # æå– info hashï¼ˆç”¨äºåŒ¹é…ç£åŠ›é“¾æ¥ï¼‰
            info_hash_match = re.search(r'xt=urn:btih:([a-zA-Z0-9]+)', new_magnet_link, re.IGNORECASE)
            if info_hash_match:
                info_hash = info_hash_match.group(1)

                # æ„å»ºç”¨äºç¬”è®°æ–‡æœ¬çš„ç£åŠ›é“¾æ¥ï¼ˆä½¿ç”¨æœªç¼–ç çš„æ–‡ä»¶åï¼‰
                text_magnet_base = re.sub(r'[&?]dn=[^&]*', '', new_magnet_link)
                text_magnet = f"{text_magnet_base}&dn={filename}"

                # åœ¨æ–‡æœ¬ä¸­æŸ¥æ‰¾åŒ…å«è¯¥ info hash çš„ç£åŠ›é“¾æ¥ï¼ˆå¯èƒ½æœ‰æˆ–æ²¡æœ‰ dn å‚æ•°ï¼‰
                # åŒ¹é…æ ¼å¼: magnet:?xt=urn:btih:{hash}(ä»»æ„å‚æ•°ç›´åˆ°æ¢è¡Œæˆ–ç»“æŸ)
                magnet_pattern = rf'magnet:\?xt=urn:btih:{re.escape(info_hash)}(?:[&?][^\n\r]*)?'

                # æ›¿æ¢æ‰¾åˆ°çš„ç£åŠ›é“¾æ¥ï¼ˆä½¿ç”¨æœªç¼–ç ç‰ˆæœ¬ï¼‰
                updated_text = re.sub(magnet_pattern, text_magnet, message_text, flags=re.IGNORECASE)

        # æ›´æ–°æ•°æ®åº“ï¼š
        # - message_text: ä½¿ç”¨æœªç¼–ç çš„æ–‡ä»¶å
        # - magnet_link: ä½¿ç”¨URLç¼–ç çš„æ–‡ä»¶å
        # - filename: æ ¡å‡†åçš„æ–‡ä»¶å
        cursor.execute(
            'UPDATE notes SET message_text = ?, magnet_link = ?, filename = ? WHERE id = ?',
            (updated_text, new_magnet_link, filename, note_id)
        )

        return cursor.rowcount > 0


def delete_note(note_id):
    """åˆ é™¤ç¬”è®°"""
    with get_db_connection() as conn:
        cursor = conn.cursor()
        
        # å…ˆè·å–ç¬”è®°ä¿¡æ¯ä»¥åˆ é™¤å…³è”çš„åª’ä½“æ–‡ä»¶
        cursor.execute('SELECT media_path, media_paths FROM notes WHERE id = ?', (note_id,))
        result = cursor.fetchone()
        
        media_files = set()
        if result:
            single_path, media_paths_json = result
            if single_path:
                media_files.add(single_path)
            if media_paths_json:
                try:
                    media_files.update(path for path in json.loads(media_paths_json) if path)
                except (json.JSONDecodeError, TypeError):
                    pass
        
        # åˆ é™¤æ•°æ®åº“è®°å½•
        cursor.execute('DELETE FROM notes WHERE id = ?', (note_id,))
        affected = cursor.rowcount
    
    # åˆ é™¤å…³è”çš„åª’ä½“æ–‡ä»¶
    for media_path in media_files:
        try:
            full_media_path = os.path.join(DATA_DIR, 'media', media_path)
            if os.path.exists(full_media_path):
                os.remove(full_media_path)
        except Exception as e:
            logger.warning(f"åˆ é™¤åª’ä½“æ–‡ä»¶å¤±è´¥: {e}")
    
    return affected > 0

# ==================== è‡ªåŠ¨æ ¡å‡†åŠŸèƒ½ ====================

def get_calibration_config():
    """è·å–è‡ªåŠ¨æ ¡å‡†é…ç½®"""
    with get_db_connection() as conn:
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        cursor.execute('SELECT * FROM auto_calibration_config WHERE id = 1')
        row = cursor.fetchone()
        return dict(row) if row else None


def update_calibration_config(config):
    """æ›´æ–°è‡ªåŠ¨æ ¡å‡†é…ç½®"""
    with get_db_connection() as conn:
        cursor = conn.cursor()
        cursor.execute('''
            UPDATE auto_calibration_config
            SET enabled = ?,
                filter_mode = ?,
                first_delay = ?,
                retry_delay_1 = ?,
                retry_delay_2 = ?,
                retry_delay_3 = ?,
                max_retries = ?,
                concurrent_limit = ?,
                timeout_per_magnet = ?,
                batch_timeout = ?
            WHERE id = 1
        ''', (
            config.get('enabled', 0),
            config.get('filter_mode', 'empty_only'),
            config.get('first_delay', 600),
            config.get('retry_delay_1', 3600),
            config.get('retry_delay_2', 14400),
            config.get('retry_delay_3', 28800),
            config.get('max_retries', 3),
            config.get('concurrent_limit', 5),
            config.get('timeout_per_magnet', 30),
            config.get('batch_timeout', 300)
        ))
        return cursor.rowcount > 0


def add_calibration_task(note_id, magnet_hash, delay_seconds=600):
    """æ·»åŠ æ ¡å‡†ä»»åŠ¡åˆ°é˜Ÿåˆ—

    Args:
        note_id: ç¬”è®°ID
        magnet_hash: ç£åŠ›é“¾æ¥çš„info hash
        delay_seconds: å»¶è¿Ÿæ‰§è¡Œæ—¶é—´ï¼ˆç§’ï¼‰
    """
    from datetime import datetime, timedelta

    try:
        with get_db_connection() as conn:
            cursor = conn.cursor()

            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒçš„å¾…å¤„ç†ä»»åŠ¡
            cursor.execute('''
                SELECT id FROM calibration_tasks
                WHERE note_id = ? AND status IN ('pending', 'retrying')
            ''', (note_id,))

            if cursor.fetchone():
                logger.debug(f"ç¬”è®° {note_id} å·²å­˜åœ¨å¾…å¤„ç†çš„æ ¡å‡†ä»»åŠ¡ï¼Œè·³è¿‡æ·»åŠ ")
                return None

            # ä½¿ç”¨ä¸­å›½æ—¶åŒºæ—¶é—´
            now_china = datetime.now(CHINA_TZ)
            next_attempt = now_china + timedelta(seconds=delay_seconds)

            # æ˜ç¡®è®¾ç½®created_atä¸ºä¸­å›½æ—¶é—´,é˜²æ­¢SQLiteçš„CURRENT_TIMESTAMPä½¿ç”¨UTC
            cursor.execute('''
                INSERT INTO calibration_tasks (note_id, magnet_hash, status, next_attempt, created_at)
                VALUES (?, ?, 'pending', ?, ?)
            ''', (note_id, magnet_hash, next_attempt.strftime('%Y-%m-%d %H:%M:%S'), now_china.strftime('%Y-%m-%d %H:%M:%S')))

            task_id = cursor.lastrowid
            logger.info(f"âœ… æ·»åŠ æ ¡å‡†ä»»åŠ¡: note_id={note_id}, task_id={task_id}, å°†åœ¨ {next_attempt.strftime('%H:%M:%S')} æ‰§è¡Œ")
            return task_id

    except Exception as e:
        logger.error(f"æ·»åŠ æ ¡å‡†ä»»åŠ¡å¤±è´¥: {e}")
        return None


def get_pending_calibration_tasks(limit=100):
    """è·å–å¾…æ‰§è¡Œçš„æ ¡å‡†ä»»åŠ¡"""
    from datetime import datetime

    with get_db_connection() as conn:
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()

        now = datetime.now(CHINA_TZ).strftime('%Y-%m-%d %H:%M:%S')

        cursor.execute('''
            SELECT * FROM calibration_tasks
            WHERE status IN ('pending', 'retrying')
            AND next_attempt <= ?
            ORDER BY next_attempt ASC
            LIMIT ?
        ''', (now, limit))

        return [dict(row) for row in cursor.fetchall()]


def update_calibration_task(task_id, status, error_message=None, next_retry_seconds=None):
    """æ›´æ–°æ ¡å‡†ä»»åŠ¡çŠ¶æ€

    Args:
        task_id: ä»»åŠ¡ID
        status: æ–°çŠ¶æ€ ('success', 'failed', 'retrying')
        error_message: é”™è¯¯æ¶ˆæ¯ï¼ˆå¯é€‰ï¼‰
        next_retry_seconds: ä¸‹æ¬¡é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼Œä»…status='retrying'æ—¶æœ‰æ•ˆï¼‰
    """
    from datetime import datetime, timedelta

    with get_db_connection() as conn:
        cursor = conn.cursor()

        now = datetime.now(CHINA_TZ).strftime('%Y-%m-%d %H:%M:%S')

        if status == 'retrying' and next_retry_seconds:
            next_attempt = datetime.now(CHINA_TZ) + timedelta(seconds=next_retry_seconds)
            cursor.execute('''
                UPDATE calibration_tasks
                SET status = ?,
                    retry_count = retry_count + 1,
                    last_attempt = ?,
                    next_attempt = ?,
                    error_message = ?
                WHERE id = ?
            ''', (status, now, next_attempt.strftime('%Y-%m-%d %H:%M:%S'), error_message, task_id))
        else:
            cursor.execute('''
                UPDATE calibration_tasks
                SET status = ?,
                    last_attempt = ?,
                    error_message = ?
                WHERE id = ?
            ''', (status, now, error_message, task_id))

        return cursor.rowcount > 0


def get_calibration_stats():
    """è·å–æ ¡å‡†ä»»åŠ¡ç»Ÿè®¡ä¿¡æ¯"""
    with get_db_connection() as conn:
        cursor = conn.cursor()

        stats = {}

        # æ€»ä»»åŠ¡æ•°
        cursor.execute('SELECT COUNT(*) FROM calibration_tasks')
        stats['total'] = cursor.fetchone()[0]

        # å„çŠ¶æ€ä»»åŠ¡æ•°
        cursor.execute('''
            SELECT status, COUNT(*) as count
            FROM calibration_tasks
            GROUP BY status
        ''')
        stats['by_status'] = {row[0]: row[1] for row in cursor.fetchall()}

        # å¾…å¤„ç†ä»»åŠ¡æ•°
        from datetime import datetime
        now = datetime.now(CHINA_TZ).strftime('%Y-%m-%d %H:%M:%S')
        cursor.execute('''
            SELECT COUNT(*) FROM calibration_tasks
            WHERE status IN ('pending', 'retrying') AND next_attempt <= ?
        ''', (now,))
        stats['ready_to_process'] = cursor.fetchone()[0]

        return stats


def delete_calibration_task(task_id):
    """åˆ é™¤æ ¡å‡†ä»»åŠ¡"""
    with get_db_connection() as conn:
        cursor = conn.cursor()
        cursor.execute('DELETE FROM calibration_tasks WHERE id = ?', (task_id,))
        return cursor.rowcount > 0


def delete_calibration_tasks_by_note_id(note_id):
    """åˆ é™¤æŒ‡å®šç¬”è®°çš„æ‰€æœ‰æ ¡å‡†ä»»åŠ¡ï¼ˆç”¨äºæ‰‹åŠ¨æ ¡å‡†æˆåŠŸåæ¸…ç†ï¼‰

    Args:
        note_id: ç¬”è®°ID

    Returns:
        int: åˆ é™¤çš„ä»»åŠ¡æ•°é‡
    """
    with get_db_connection() as conn:
        cursor = conn.cursor()
        cursor.execute('DELETE FROM calibration_tasks WHERE note_id = ?', (note_id,))
        deleted_count = cursor.rowcount
        logger.info(f"æ¸…ç†äº† {deleted_count} ä¸ªè‡ªåŠ¨æ ¡å‡†ä»»åŠ¡ï¼ˆnote_id={note_id}ï¼‰")
        return deleted_count


def clear_completed_calibration_tasks(days=7):
    """æ¸…ç†å·²å®Œæˆçš„æ ¡å‡†ä»»åŠ¡

    Args:
        days: ä¿ç•™æœ€è¿‘Nå¤©çš„è®°å½•
    """
    from datetime import datetime, timedelta

    with get_db_connection() as conn:
        cursor = conn.cursor()
        cutoff_date = (datetime.now(CHINA_TZ) - timedelta(days=days)).strftime('%Y-%m-%d %H:%M:%S')

        cursor.execute('''
            DELETE FROM calibration_tasks
            WHERE status = 'success'
            AND created_at < ?
        ''', (cutoff_date,))

        deleted = cursor.rowcount
        logger.info(f"æ¸…ç†äº† {deleted} æ¡å·²å®Œæˆçš„æ ¡å‡†ä»»åŠ¡ï¼ˆ{days}å¤©å‰ï¼‰")
        return deleted


def get_all_calibration_tasks(status=None, limit=100, offset=0):
    """è·å–æ‰€æœ‰æ ¡å‡†ä»»åŠ¡ï¼ˆç”¨äºWebç•Œé¢æ˜¾ç¤ºï¼‰

    Args:
        status: è¿‡æ»¤çŠ¶æ€ï¼ˆå¯é€‰ï¼‰
        limit: è¿”å›æ•°é‡é™åˆ¶
        offset: åç§»é‡
    """
    with get_db_connection() as conn:
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()

        query = 'SELECT * FROM calibration_tasks WHERE 1=1'
        params = []

        if status:
            query += ' AND status = ?'
            params.append(status)

        query += ' ORDER BY created_at DESC LIMIT ? OFFSET ?'
        params.extend([limit, offset])

        cursor.execute(query, params)
        return [dict(row) for row in cursor.fetchall()]


def toggle_favorite(note_id):
    """åˆ‡æ¢ç¬”è®°æ”¶è—çŠ¶æ€"""
    with get_db_connection() as conn:
        cursor = conn.cursor()
        cursor.execute('UPDATE notes SET is_favorite = 1 - is_favorite WHERE id = ?', (note_id,))
        return cursor.rowcount > 0


# åˆå§‹åŒ–æ•°æ®åº“ï¼ˆç¡®ä¿è¡¨å’Œé»˜è®¤ç”¨æˆ·å­˜åœ¨ï¼‰
init_database()
